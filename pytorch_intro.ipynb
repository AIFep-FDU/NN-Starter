{"cells":[{"cell_type":"markdown","metadata":{"id":"WFmLsCjpZfrf"},"source":["# Pytorch Introduction\n","\n","## Table of Content\n","1. Numpy\n","2. Pytorch\n","3. NN-XOR"]},{"cell_type":"markdown","metadata":{"id":"LTBnlzhUcxRz"},"source":["# 1. Numpy\n","\n","Numpy is an optimized library for matrix and vector computation.\n","\n","More information can be found in https://numpy.org/doc/stable/."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":523,"status":"ok","timestamp":1681658420359,"user":{"displayName":"Dr CAO Yixin _","userId":"02213333189428679281"},"user_tz":-480},"id":"4aHyi2TvEIFH","outputId":"8133b3c7-03c5-41fe-c974-5500655a2120"},"outputs":[{"name":"stdout","output_type":"stream","text":["x: [1 2 3]\n","y: [[3 4 5]]\n","z: [[6 7]\n"," [8 9]]\n","The shape of x is:  (3,) x is a 1-d vector!\n","The shape of y is:  (1, 3) y is a row vector!\n","The shape of z is:  (2, 2) z is a matrix!\n"]}],"source":["import numpy as np\n","\n","np.random.seed(2)  # fix the random seed for reproducibility\n","\n","x = np.array([1,2,3])       # create a numpy array from a list\n","y = np.array([[3,4,5]])\n","z = np.array([[6,7], [8,9]])\n","\n","print(\"x:\", x)\n","print(\"y:\", y)\n","print(\"z:\", z)\n","\n","print(\"The shape of x is: \", x.shape, \"x is a 1-d vector!\")\n","print(\"The shape of y is: \", y.shape, \"y is a row vector!\")\n","print(\"The shape of z is: \", z.shape, \"z is a matrix!\")"]},{"cell_type":"markdown","metadata":{"id":"2YnAjgfVE0LH"},"source":["## numpy array axis\n","\n","Some useful function: np.max, np.min, np.amax, np.sum, np.mean, ..."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":503,"status":"ok","timestamp":1681658426667,"user":{"displayName":"Dr CAO Yixin _","userId":"02213333189428679281"},"user_tz":-480},"id":"7uRgEJUBE01A","outputId":"0cedfdec-1ef1-4b74-8e38-eb21d09ab91c"},"outputs":[{"name":"stdout","output_type":"stream","text":["[[1 2]\n"," [5 4]\n"," [3 6]]\n","[2 5 6]\n","[[2]\n"," [5]\n"," [6]]\n"]}],"source":["x = np.array([[1,2], [5,4], [3,6]])\n","print(x)\n","print(np.max(x, axis=1))\n","print(np.max(x, axis=1, keepdims=True))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":666,"status":"ok","timestamp":1681658429657,"user":{"displayName":"Dr CAO Yixin _","userId":"02213333189428679281"},"user_tz":-480},"id":"EvRqzNjUE9QH","outputId":"dd900527-e8a0-43d6-b093-904ca110a4b4"},"outputs":[{"data":{"text/plain":["array([[0.4359949 , 0.02592623, 0.54966248, 0.43532239],\n","       [0.4203678 , 0.33033482, 0.20464863, 0.61927097],\n","       [0.29965467, 0.26682728, 0.62113383, 0.52914209]])"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["x = np.random.random( (3,4) )       # randomly initialize a (3,4) matrix\n","x[:]                                # select everything"]},{"cell_type":"markdown","metadata":{"id":"5SdOryFWE5FH"},"source":["## Numpy indexing"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":528,"status":"ok","timestamp":1681658432504,"user":{"displayName":"Dr CAO Yixin _","userId":"02213333189428679281"},"user_tz":-480},"id":"qJW-8kRtE51X","outputId":"875f3fb2-e34a-4b0a-b2b9-b389993d7f27"},"outputs":[{"data":{"text/plain":["array([[0.4359949 , 0.02592623, 0.54966248, 0.43532239],\n","       [0.29965467, 0.26682728, 0.62113383, 0.52914209]])"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["x[np.array([0, 2]), :]              # select the 0th and 2nd rows"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1681658433858,"user":{"displayName":"Dr CAO Yixin _","userId":"02213333189428679281"},"user_tz":-480},"id":"-oS7yVNUFRQw","outputId":"ca97864e-5f22-460b-b9a3-dc899eef82e5"},"outputs":[{"data":{"text/plain":["array([0.33033482, 0.20464863])"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["x[1, 1:3]                           # select 1st row as 1-D vector, and then the 1st through 2nd elements"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1681658435725,"user":{"displayName":"Dr CAO Yixin _","userId":"02213333189428679281"},"user_tz":-480},"id":"hJWvBguEFVLX","outputId":"77cd1f42-be85-4eb4-8367-d7aac024cd62"},"outputs":[{"data":{"text/plain":["array([0.4359949 , 0.02592623, 0.43532239, 0.4203678 , 0.33033482,\n","       0.20464863, 0.29965467, 0.26682728])"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["x[x<0.5]                            # boolean indexing"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":498,"status":"ok","timestamp":1681658438629,"user":{"displayName":"Dr CAO Yixin _","userId":"02213333189428679281"},"user_tz":-480},"id":"WS7u8S8NFYBX","outputId":"9d5dee72-0d3a-427d-84d1-b2cbb5800313"},"outputs":[{"name":"stdout","output_type":"stream","text":["(3,)\n","(3, 1)\n","[[1]\n"," [2]\n"," [3]]\n"]}],"source":["y = np.array([1,2,3])\n","print(y.shape)\n","y2 = y[:, np.newaxis]                 # convert to 3-d vector of shape (3, 4, 1)\n","print(y2.shape)\n","print(y2)    "]},{"cell_type":"markdown","metadata":{"id":"C7CFRc5UIItn"},"source":["## numpy operation and broadcasting\n","\n","matrix operation: np.dot, np.matmul, .T, ......\n","\n","element-wise operator: +, -, *, **, /"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":850,"status":"ok","timestamp":1681658441451,"user":{"displayName":"Dr CAO Yixin _","userId":"02213333189428679281"},"user_tz":-480},"id":"fo_nVsI2IH2v","outputId":"6e98dba9-cd07-41d5-8422-5067a95ccd1c"},"outputs":[{"name":"stdout","output_type":"stream","text":["A: [[0.13457995 0.51357812]\n"," [0.18443987 0.78533515]\n"," [0.85397529 0.49423684]]\n","B: [[0.84656149]\n"," [0.07964548]]\n"]}],"source":["A = np.random.random( (3,2) )\n","B = np.random.random( (2,1) )\n","print(\"A:\", A)\n","print(\"B:\", B)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":900,"status":"ok","timestamp":1681658443472,"user":{"displayName":"Dr CAO Yixin _","userId":"02213333189428679281"},"user_tz":-480},"id":"rtW8REheIPQC","outputId":"49ce9f16-eca1-424c-c3ee-4867c94b329c"},"outputs":[{"data":{"text/plain":["array([[0.15483437],\n","       [0.21868808],\n","       [0.76230632]])"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["C = np.dot(A, B)                 # matrix product, also can use np.matmul, (3, 2) * (2, 1) leads to (3, 1)\n","C"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":332,"status":"ok","timestamp":1681658445178,"user":{"displayName":"Dr CAO Yixin _","userId":"02213333189428679281"},"user_tz":-480},"id":"QVCKexYMIWAK","outputId":"ac893b24-edb3-489d-f974-f2a3b17206d2"},"outputs":[{"data":{"text/plain":["array([[0.13457995, 0.18443987, 0.85397529],\n","       [0.51357812, 0.78533515, 0.49423684]])"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["A.T                               # matrix transpose"]},{"cell_type":"markdown","metadata":{"id":"AChfYHNAIZ5S"},"source":["When operating on two arrays, NumPy compares their shapes element-wise. It starts with the trailing (i.e. rightmost) dimensions and works its way left. Two dimensions are compatible when:\n","\n","1. they are equal, or\n","2. one of them is 1 (in which case, elements on the axis are repeated along the dimension)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1681658446735,"user":{"displayName":"Dr CAO Yixin _","userId":"02213333189428679281"},"user_tz":-480},"id":"CQgOwRR5IYho","outputId":"7e794c1a-8b65-4d31-eaf2-acf431d29eb6"},"outputs":[{"data":{"text/plain":["array([[0.98114143, 1.03100135, 1.70053678],\n","       [0.5932236 , 0.86498062, 0.57388231]])"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["D = A.T                           # D: (2,3), B: (2,1)\n","B+D                               # Broadcasting: adds B to each column of D"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":694,"status":"ok","timestamp":1681658448849,"user":{"displayName":"Dr CAO Yixin _","userId":"02213333189428679281"},"user_tz":-480},"id":"Mq1Hq_l1IqQU","outputId":"3471a0cf-edc4-4637-8865-06b56c8dfb2f"},"outputs":[{"data":{"text/plain":["array([[0.1139302 , 0.04090417],\n","       [0.15613969, 0.06254839],\n","       [0.72294259, 0.03936373]])"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["E = B.T                           # E: (1, 2), A: (3,2)\n","A*E                               # Broadcasting: multiples E (element-wise) with each row of A"]},{"cell_type":"markdown","metadata":{"id":"FIELEFOfYEeY"},"source":["# Pytorch\n","\n","Here is a simple example to get familiar with Pytorch for writing your own neural networks. PyTorch is an open source machine learning framework that allows you to write your own neural networks and optimize them efficiently. However, PyTorch is not the only framework of its kind. Alternatives to PyTorch include [TensorFlow](https://www.tensorflow.org/), [JAX](https://github.com/google/jax#quickstart-colab-in-the-cloud) and [Caffe](http://caffe.berkeleyvision.org/). Below content is simplied from [Pytorch tutorial](https://colab.research.google.com/github/phlippe/uvadlc_notebooks/blob/master/docs/tutorial_notebooks/tutorial2/Introduction_to_PyTorch.ipynb#scrollTo=t7y2I3UKXh7Z).\n","\n","There are also many great tutorials online, including the [\"60-min blitz\"](https://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html) on the official [PyTorch website](https://pytorch.org/tutorials/).\n","\n","Let's start with importing Pytorch. The package is called `torch`, based on its original framework [Torch](http://torch.ch/). As a first step, we can check its version:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4817,"status":"ok","timestamp":1681658527768,"user":{"displayName":"Dr CAO Yixin _","userId":"02213333189428679281"},"user_tz":-480},"id":"qPT7AjooYK_H","outputId":"14d74b14-6eee-46c8-8c08-ba3f9e27dff0"},"outputs":[{"name":"stdout","output_type":"stream","text":["Using torch 2.0.0+cu118\n"]}],"source":["import torch\n","print(\"Using torch\", torch.__version__)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":261,"status":"ok","timestamp":1681658529855,"user":{"displayName":"Dr CAO Yixin _","userId":"02213333189428679281"},"user_tz":-480},"id":"yjUH2Qt2a1lT","outputId":"0a5aa5fa-38f7-4bcf-b467-76c2038635a3"},"outputs":[{"data":{"text/plain":["<torch._C.Generator at 0x7f5da0400050>"]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["torch.manual_seed(42) # Setting the seed for reproducibility, similar with numpy.random.seed as mentioned above"]},{"cell_type":"markdown","metadata":{"id":"W9zKfiE4Y_v-"},"source":["### Tensors\n","\n","Tensors are the PyTorch equivalent to Numpy arrays, with the addition to also have support for GPU acceleration (more on that later).\n","The name \"tensor\" is a generalization of concepts you already know. For instance, a vector is a 1-D tensor, and a matrix a 2-D tensor. When working with neural networks, we will use tensors of various shapes and number of dimensions.\n","\n","Most common functions you know from numpy can be used on tensors as well. Actually, since numpy arrays are so similar to tensors, we can convert most tensors to numpy arrays (and back) but we don't need it too often.\n","\n","#### Initialization\n","\n","Let's first start by looking at different ways of creating a tensor. There are many possible options, the simplest one is to call `torch.Tensor` passing the desired shape as input argument:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":495,"status":"ok","timestamp":1681658547446,"user":{"displayName":"Dr CAO Yixin _","userId":"02213333189428679281"},"user_tz":-480},"id":"6OnEItyvY-8Y","outputId":"017ccfbe-bfc0-48bb-d42d-6de01d04ad85"},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([[[7.0696e+28, 7.1831e+22, 3.9158e-02, 1.1705e-19],\n","         [1.3563e-19, 1.2686e+31, 6.7411e+22, 1.6020e-19],\n","         [1.8728e+31, 1.3556e-19, 1.3563e-19, 7.1220e+28]],\n","\n","        [[1.9747e-19, 3.1777e+30, 6.8306e+22, 1.1632e+33],\n","         [1.6529e+19, 1.8990e+28, 3.7561e-14, 1.3556e-19],\n","         [1.3563e-19, 1.3563e-19, 6.7331e+22, 1.1866e+27]]])\n"]}],"source":["x = torch.Tensor(2, 3, 4)\n","print(x)"]},{"cell_type":"markdown","metadata":{"id":"utd4xDoLZ8EG"},"source":["The function `torch.Tensor` allocates memory for the desired tensor, but reuses any values that have already been in the memory. To directly assign values to the tensor during initialization, there are many alternatives including:\n","\n","* `torch.zeros`: Creates a tensor filled with zeros\n","* `torch.ones`: Creates a tensor filled with ones\n","* `torch.rand`: Creates a tensor with random values uniformly sampled between 0 and 1\n","* `torch.randn`: Creates a tensor with random values sampled from a normal distribution with mean 0 and variance 1\n","* `torch.arange`: Creates a tensor containing the values $N,N+1,N+2,...,M$\n","* `torch.Tensor` (input list): Creates a tensor from the list elements you provide"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":500,"status":"ok","timestamp":1681658549707,"user":{"displayName":"Dr CAO Yixin _","userId":"02213333189428679281"},"user_tz":-480},"id":"TAjiAKh6blmy","outputId":"a00d7c33-a33f-4c48-a8c3-1142798ed93b"},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([[1., 2.],\n","        [3., 4.]])\n"]}],"source":["# Create a tensor from a (nested) list\n","x = torch.Tensor([[1, 2], [3, 4]])\n","print(x)"]},{"cell_type":"markdown","metadata":{"id":"77HeyTzJbpxK"},"source":["You can obtain the shape of a tensor in the same way as in numpy (`x.shape`), or using the `.size` method.\n","\n","Note that shape verification is very important!"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":282,"status":"ok","timestamp":1681658594629,"user":{"displayName":"Dr CAO Yixin _","userId":"02213333189428679281"},"user_tz":-480},"id":"ZHr14MOMbsgK","outputId":"210dbf44-8756-4bf1-c4b6-7905d4e6a730"},"outputs":[{"name":"stdout","output_type":"stream","text":["Shape: torch.Size([2, 2])\n","Size: torch.Size([2, 2])\n","Size: 2 2\n"]}],"source":["shape = x.shape\n","print(\"Shape:\", x.shape)\n","\n","size = x.size()\n","print(\"Size:\", size)\n","\n","dim1, dim2 = x.size()\n","print(\"Size:\", dim1, dim2)"]},{"cell_type":"markdown","metadata":{"id":"218ZOVGcbuSz"},"source":["#### Tensor to Numpy, and Numpy to Tensor\n","\n","Tensors can be converted to numpy arrays, and numpy arrays back to tensors. To transform a numpy array into a tensor, we can use the function `torch.from_numpy`."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":321,"status":"ok","timestamp":1681658649680,"user":{"displayName":"Dr CAO Yixin _","userId":"02213333189428679281"},"user_tz":-480},"id":"z8G73PTJYv7K","outputId":"061d9ab8-6d5c-49a2-e3b4-fc0efee194ed"},"outputs":[{"name":"stdout","output_type":"stream","text":["Numpy array: [[1 2]\n"," [3 4]]\n","PyTorch tensor: tensor([[1, 2],\n","        [3, 4]])\n"]}],"source":["np_arr = np.array([[1, 2], [3, 4]])\n","tensor = torch.from_numpy(np_arr)\n","\n","print(\"Numpy array:\", np_arr)\n","print(\"PyTorch tensor:\", tensor)"]},{"cell_type":"markdown","metadata":{"id":"2zoiWkyNcPPZ"},"source":["To transform a PyTorch tensor back to a numpy array, we can use the function `.numpy()` on tensors:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":487,"status":"ok","timestamp":1681658653877,"user":{"displayName":"Dr CAO Yixin _","userId":"02213333189428679281"},"user_tz":-480},"id":"szX9sTs2cQo5","outputId":"99245b44-8574-48ff-b832-5ed8df7ee77c"},"outputs":[{"name":"stdout","output_type":"stream","text":["PyTorch tensor: tensor([0, 1, 2, 3])\n","Numpy array: [0 1 2 3]\n"]}],"source":["tensor = torch.arange(4)\n","np_arr = tensor.numpy()\n","\n","print(\"PyTorch tensor:\", tensor)\n","print(\"Numpy array:\", np_arr)"]},{"cell_type":"markdown","metadata":{"id":"Z6u83dpBcWFx"},"source":["The conversion of tensors to numpy require the tensor to be on the CPU, and not the GPU (more on GPU support in a later section). In case you have a tensor on GPU, you need to call `.cpu()` on the tensor beforehand. Hence, you get a line like `np_arr = tensor.cpu().numpy()`."]},{"cell_type":"markdown","metadata":{"id":"ejapJvozb8Zn"},"source":["### Operations\n","\n","Most operations that exist in numpy, also exist in PyTorch. A full list of operations can be found in the [PyTorch documentation](https://pytorch.org/docs/stable/tensors.html#), but we will review the most important ones here.\n","\n","The simplest operation is to add two tensors:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":704,"status":"ok","timestamp":1681658657687,"user":{"displayName":"Dr CAO Yixin _","userId":"02213333189428679281"},"user_tz":-480},"id":"Z6kiCbvUcDh-","outputId":"d7875d6c-301f-4c81-c5d1-3b992e937a06"},"outputs":[{"name":"stdout","output_type":"stream","text":["X1 tensor([[0.8823, 0.9150, 0.3829],\n","        [0.9593, 0.3904, 0.6009]])\n","X2 tensor([[0.2566, 0.7936, 0.9408],\n","        [0.1332, 0.9346, 0.5936]])\n","Y tensor([[1.1388, 1.7086, 1.3236],\n","        [1.0925, 1.3250, 1.1945]])\n"]}],"source":["x1 = torch.rand(2, 3)\n","x2 = torch.rand(2, 3)\n","y = x1 + x2\n","\n","print(\"X1\", x1)\n","print(\"X2\", x2)\n","print(\"Y\", y)"]},{"cell_type":"markdown","metadata":{"id":"w7S0sJdScnlv"},"source":["Another common operation aims at changing the shape of a tensor. A tensor of size (2,3) can be re-organized to any other shape with the same number of elements (e.g. a tensor of size (6), or (3,2), ...). In PyTorch, this operation is called `view`:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1681658659898,"user":{"displayName":"Dr CAO Yixin _","userId":"02213333189428679281"},"user_tz":-480},"id":"M8Dbq3TZcppt","outputId":"93c520e1-ff7e-4e24-ebd9-3e4cbe0ad113"},"outputs":[{"name":"stdout","output_type":"stream","text":["X tensor([0, 1, 2, 3, 4, 5])\n","X tensor([[0, 1, 2],\n","        [3, 4, 5]])\n","X tensor([[0, 3],\n","        [1, 4],\n","        [2, 5]])\n"]}],"source":["x = torch.arange(6)\n","print(\"X\", x)\n","\n","x = x.view(2, 3)\n","print(\"X\", x)\n","\n","x = x.permute(1, 0) # Swapping dimension 0 and 1\n","print(\"X\", x)"]},{"cell_type":"markdown","metadata":{"id":"24XBMgFSc6Ca"},"source":["Other commonly used operations include matrix multiplications, which are essential for neural networks. Quite often, we have an input vector $\\mathbf{x}$, which is transformed using a learned weight matrix $\\mathbf{W}$. There are multiple ways and functions to perform matrix multiplication, some of which we list below:\n","\n","* `torch.matmul`: Performs the matrix product over two tensors, where the specific behavior depends on the dimensions. If both inputs are matrices (2-dimensional tensors), it performs the standard matrix product. For higher dimensional inputs, the function supports broadcasting (for details see the [documentation](https://pytorch.org/docs/stable/generated/torch.matmul.html?highlight=matmul#torch.matmul)). Can also be written as `a @ b`, similar to numpy. \n","* `torch.mm`: Performs the matrix product over two matrices, but doesn't support broadcasting (see [documentation](https://pytorch.org/docs/stable/generated/torch.mm.html?highlight=torch%20mm#torch.mm))\n","* `torch.bmm`: Performs the matrix product with a support batch dimension. If the first tensor $T$ is of shape ($b\\times n\\times m$), and the second tensor $R$ ($b\\times m\\times p$), the output $O$ is of shape ($b\\times n\\times p$), and has been calculated by performing $b$ matrix multiplications of the submatrices of $T$ and $R$: $O_i = T_i @ R_i$\n","* `torch.einsum`: Performs matrix multiplications and more (i.e. sums of products) using the Einstein summation convention. Explanation of the Einstein sum can be found in assignment 1.\n","\n","Usually, we use `torch.matmul` or `torch.bmm`. We can try a matrix multiplication with `torch.matmul` below."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":498,"status":"ok","timestamp":1681658663436,"user":{"displayName":"Dr CAO Yixin _","userId":"02213333189428679281"},"user_tz":-480},"id":"8fQbIK0qc-vb","outputId":"6db6cfb3-9582-4e85-e225-43677661ecd9"},"outputs":[{"name":"stdout","output_type":"stream","text":["X tensor([[0, 1, 2],\n","        [3, 4, 5]])\n","W tensor([[0, 1, 2],\n","        [3, 4, 5],\n","        [6, 7, 8]])\n","h tensor([[15, 18, 21],\n","        [42, 54, 66]])\n"]}],"source":["x = torch.arange(6)\n","x = x.view(2, 3)\n","print(\"X\", x)\n","\n","W = torch.arange(9).view(3, 3) # We can also stack multiple operations in a single line\n","print(\"W\", W)\n","\n","h = torch.matmul(x, W) # Verify the result by calculating it by hand too!\n","print(\"h\", h)"]},{"cell_type":"markdown","metadata":{"id":"oyXj4spXdKqo"},"source":["### Indexing\n","\n","We often have the situation where we need to select a part of a tensor. Indexing works just like in numpy, so let's try it:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":392,"status":"ok","timestamp":1681658665805,"user":{"displayName":"Dr CAO Yixin _","userId":"02213333189428679281"},"user_tz":-480},"id":"TIAGtTRCdN4y","outputId":"950ba35f-2fa9-4d44-f3b2-66048036708d"},"outputs":[{"name":"stdout","output_type":"stream","text":["X tensor([[ 0,  1,  2,  3],\n","        [ 4,  5,  6,  7],\n","        [ 8,  9, 10, 11]])\n","tensor([1, 5, 9])\n","tensor([0, 1, 2, 3])\n","tensor([3, 7])\n","tensor([[ 4,  5,  6,  7],\n","        [ 8,  9, 10, 11]])\n"]}],"source":["x = torch.arange(12).view(3, 4)\n","print(\"X\", x)\n","\n","print(x[:, 1])   # Second column\n","\n","print(x[0])      # First row\n","\n","print(x[:2, -1]) # First two rows, last column\n","\n","print(x[1:3, :]) # Middle two rows"]},{"cell_type":"markdown","metadata":{"id":"kuameqWJdb_4"},"source":["### Dynamic Computation Graph and Backpropagation\n","\n","One of the main reasons for using PyTorch in Deep Learning projects is that we can automatically get **gradients/derivatives** of functions that we define. We will mainly use PyTorch for implementing neural networks, and they are just fancy functions. If we use weight matrices in our function that we want to learn, then those are called the **parameters** or simply the **weights**.\n","\n","If our neural network would output a single scalar value, we would talk about taking the **derivative**, but you will see that quite often we will have **multiple** output variables (\"values\"); in that case we talk about **gradients**. It's a more general term.\n","\n","Given an input $\\mathbf{x}$, we define our function by **manipulating** that input, usually by matrix-multiplications with weight matrices and additions with so-called bias vectors. As we manipulate our input, we are automatically creating a **computational graph**. This graph shows how to arrive at our output from our input. \n","PyTorch is a **define-by-run** framework; this means that we can just do our manipulations, and PyTorch will keep track of that graph for us. Thus, we create a dynamic computation graph along the way.\n","\n","So, to recap: the only thing we have to do is to compute the **output**, and then we can ask PyTorch to automatically get the **gradients**. \n","\n","> **Note:  Why do we want gradients?** Consider that we have defined a function, a neural net, that is supposed to compute a certain output $y$ for an input vector $\\mathbf{x}$. We then define an **error measure** that tells us how wrong our network is; how bad it is in predicting output $y$ from input $\\mathbf{x}$. Based on this error measure, we can use the gradients to **update** the weights $\\mathbf{W}$ that were responsible for the output, so that the next time we present input $\\mathbf{x}$ to our network, the output will be closer to what we want.\n","\n","The first thing we have to do is to specify which tensors require gradients. By default, when we create a tensor, it does not require gradients."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":596,"status":"ok","timestamp":1681658668882,"user":{"displayName":"Dr CAO Yixin _","userId":"02213333189428679281"},"user_tz":-480},"id":"VdAeIdpkdi-9","outputId":"b5d2d264-c212-44d7-8e03-8cf666f86e18"},"outputs":[{"name":"stdout","output_type":"stream","text":["False\n"]}],"source":["x = torch.ones((3,))\n","print(x.requires_grad)"]},{"cell_type":"markdown","metadata":{"id":"UWTF-tkMzfnR"},"source":["We can change this for an existing tensor using the function `requires_grad_()` (underscore indicating that this is a in-place operation). Alternatively, when creating a tensor, you can pass the argument `requires_grad=True` to most initializers we have seen above."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":443,"status":"ok","timestamp":1681658671264,"user":{"displayName":"Dr CAO Yixin _","userId":"02213333189428679281"},"user_tz":-480},"id":"44DYa6D6dm4M","outputId":"441074ec-1b2b-4363-a760-0bc098a8d892"},"outputs":[{"name":"stdout","output_type":"stream","text":["True\n"]}],"source":["x.requires_grad_(True)\n","print(x.requires_grad)"]},{"cell_type":"markdown","metadata":{"id":"rqXwepIQzN2p"},"source":["## Learning by example: Continuous XOR\n","\n","If we want to build a neural network in PyTorch, we could specify all our parameters (weight matrices, bias vectors) using `Tensors` (with `requires_grad=True`), ask PyTorch to calculate the gradients and then adjust the parameters. But things can quickly get cumbersome if we have a lot of parameters. In PyTorch, there is a package called `torch.nn` that makes building neural networks more convenient. \n","\n","We will introduce the libraries and all additional parts you might need to train a neural network in PyTorch, using a simple example classifier on a simple yet well known example: XOR. Given two binary inputs $x_1$ and $x_2$, the label to predict is $1$ if either $x_1$ or $x_2$ is $1$ while the other is $0$, or the label is $0$ in all other cases.\n","\n","| x1 | x2 | XOR |\n","|----|:--:|----:|\n","| 0  |  0 |  0  |\n","| 0  |  1 |  1  |\n","| 1  |  0 |  1  |\n","| 1  |  1 |  0  |"]},{"cell_type":"markdown","metadata":{"id":"LG6IZuAtfjS6"},"source":["### The model\n","\n","The package `torch.nn` defines a series of useful classes like linear networks layers, activation functions, loss functions etc. A full list can be found [here](https://pytorch.org/docs/stable/nn.html). In case you need a certain network layer, check the documentation of the package first before writing the layer yourself as the package likely contains the code for it already. We import it below.\n","\n","Additionally to `torch.nn`, there is also `torch.nn.functional`. It contains functions that are used in network layers. This is in contrast to `torch.nn` which defines them as `nn.Modules` (more on it below), and `torch.nn` actually uses a lot of functionalities from `torch.nn.functional`. Hence, the functional package is useful in many situations, and so we import it as well here."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qoG4aaQ18ST_"},"outputs":[],"source":["import torch.nn as nn\n","import torch.nn.functional as F"]},{"cell_type":"markdown","metadata":{"id":"lFIDknzPzSop"},"source":["### nn.Module\n","\n","In PyTorch, a neural network is built up out of modules. Modules can contain other modules, and a neural network is considered to be a module itself as well. The basic template of a module is as follows:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fxRSmOMTwcvI"},"outputs":[],"source":["class MyModule(nn.Module):\n","    \n","    def __init__(self):\n","        super().__init__()\n","        # Some init for my module\n","        \n","    def forward(self, x):\n","        # Function for performing the calculation of the module.\n","        pass"]},{"cell_type":"markdown","metadata":{"id":"CbDMa6H7101u"},"source":["The forward function is where the computation of the module is taken place, and is executed when you call the module (`nn = MyModule(); nn(x)`). In the init function, we usually create the parameters of the module, using `nn.Parameter`, or defining other modules that are used in the forward function. The backward calculation is done automatically, but could be overwritten as well if wanted.\n","\n","Let's build a simple classifier for XOR function!\n","\n","We will take two input neurons, four hidden neurons, and a single output neuron for binary classification. We will apply a Tanh as the activation function."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ske0iL2F0FYi"},"outputs":[],"source":["class SimpleClassifier(nn.Module):\n","\n","    def __init__(self, num_inputs, num_hidden, num_outputs):\n","        super().__init__()\n","        # Initialize the modules we need to build the network\n","        self.linear1 = nn.Linear(num_inputs, num_hidden)\n","        self.act_fn = nn.Tanh()\n","        ######################################################\n","        #### 完善代码1：自定义self.linear2，注意输入维度和输出维度\n","        #### self.linear2 = \n","        ######################################################\n","\n","    def forward(self, x):\n","        # Perform the calculation of the model to determine the prediction\n","        x = self.linear1(x)\n","        x = self.act_fn(x)\n","        x = self.linear2(x)\n","        \n","        return x.squeeze(dim=1) # Output is [Batch size, 1], but we want [Batch size]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":519,"status":"ok","timestamp":1681658748954,"user":{"displayName":"Dr CAO Yixin _","userId":"02213333189428679281"},"user_tz":-480},"id":"al_sKfOFg9It","outputId":"9f52edaf-7a5f-4449-9256-3a276b88aa92"},"outputs":[{"name":"stdout","output_type":"stream","text":["SimpleClassifier(\n","  (linear1): Linear(in_features=2, out_features=4, bias=True)\n","  (act_fn): Tanh()\n","  (linear2): Linear(in_features=4, out_features=1, bias=True)\n",")\n"]}],"source":["model = SimpleClassifier(num_inputs=2, num_hidden=4, num_outputs=1)\n","# Printing a module shows all its submodules\n","print(model)"]},{"cell_type":"markdown","metadata":{"id":"5VEsUk7khDYS"},"source":["Printing the model lists all submodules it contains. The parameters of a module can be obtained by using its `parameters()` functions, or `named_parameters()` to get a name to each parameter object. For our small neural network, we have the following parameters:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":332,"status":"ok","timestamp":1681658769255,"user":{"displayName":"Dr CAO Yixin _","userId":"02213333189428679281"},"user_tz":-480},"id":"KMTbXLrahC4h","outputId":"71d54d62-f927-4f34-ff2c-3544cd3faa99"},"outputs":[{"name":"stdout","output_type":"stream","text":["Parameter linear1.weight, shape torch.Size([4, 2])\n","Parameter linear1.bias, shape torch.Size([4])\n","Parameter linear2.weight, shape torch.Size([1, 4])\n","Parameter linear2.bias, shape torch.Size([1])\n"]}],"source":["for name, param in model.named_parameters():\n","    print(f\"Parameter {name}, shape {param.shape}\")"]},{"cell_type":"markdown","metadata":{"id":"WXCZLIYqhX0N"},"source":["Each linear layer has a weight matrix of the shape `[output, input]`, and a bias of the shape `[output]`. The tanh activation function does not have any parameters. Note that parameters are only registered for `nn.Module` objects that are direct object attributes, i.e. `self.a = ...`. If you define a list of modules, the parameters of those are not registered for the outer module and can cause some issues when you try to optimize your module. There are alternatives, like `nn.ModuleList`, `nn.ModuleDict` and `nn.Sequential`, that allow you to have different data structures of modules."]},{"cell_type":"markdown","metadata":{"id":"5uP1wc3a4-CB"},"source":["### Datasets\n","\n","We provide XOR dataset for training and evaluating the above model.\n","\n","PyTorch also provides a few functionalities to load the training and test data efficiently, summarized in the package `torch.utils.data`.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2Cl7oBb7iG_N"},"outputs":[],"source":["import torch.utils.data as data\n","\n","class XORDataset(data.Dataset):\n","\n","    def __init__(self, size, std=0.1):\n","        \"\"\"\n","        Inputs:\n","            size - Number of data points we want to generate\n","            std - Standard deviation of the noise (see generate_continuous_xor function)\n","        \"\"\"\n","        super().__init__()\n","        self.size = size\n","        self.std = std\n","        self.generate_continuous_xor()\n","\n","    def generate_continuous_xor(self):\n","        # Each data point in the XOR dataset has two variables, x and y, that can be either 0 or 1\n","        # The label is their XOR combination, i.e. 1 if only x or only y is 1 while the other is 0.\n","        # If x=y, the label is 0.\n","        data = torch.randint(low=0, high=2, size=(self.size, 2), dtype=torch.float32)\n","        ##########################################################################\n","        ## 完善代码2：根据data的值生成异或标签label\n","        ## label = \n","        ##########################################################################\n","        # To make it slightly more challenging, we add a bit of gaussian noise to the data points.\n","        data += self.std * torch.randn(data.shape)\n","\n","        self.data = data\n","        self.label = label\n","\n","    def __len__(self):\n","        # Number of data point we have. Alternatively self.data.shape[0], or self.label.shape[0]\n","        return self.size\n","\n","    def __getitem__(self, idx):\n","        # Return the idx-th data point of the dataset\n","        # If we have multiple things to return (data point and label), we can return them as tuple\n","        data_point = self.data[idx]\n","        data_label = self.label[idx]\n","        return data_point, data_label"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":494,"status":"ok","timestamp":1681658776057,"user":{"displayName":"Dr CAO Yixin _","userId":"02213333189428679281"},"user_tz":-480},"id":"F0OWh-hFiJFm","outputId":"3c64de08-6e22-42a8-8450-9fd827aabbd3"},"outputs":[{"name":"stdout","output_type":"stream","text":["Size of dataset: 200\n","Data point 0: (tensor([ 0.9638, -0.1692]), tensor(1))\n"]}],"source":["dataset = XORDataset(size=200)\n","print(\"Size of dataset:\", len(dataset))\n","print(\"Data point 0:\", dataset[0])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1338,"status":"ok","timestamp":1681658779134,"user":{"displayName":"Dr CAO Yixin _","userId":"02213333189428679281"},"user_tz":-480},"id":"QofaSbTdiQK4","outputId":"cf84c42d-6021-48fb-bd67-5795995d7f1b"},"outputs":[{"name":"stderr","output_type":"stream","text":["<ipython-input-42-1e09ea66edf7>:5: DeprecationWarning: `set_matplotlib_formats` is deprecated since IPython 7.23, directly use `matplotlib_inline.backend_inline.set_matplotlib_formats()`\n","  set_matplotlib_formats('svg', 'pdf') # For export\n"]}],"source":["## Imports for plotting\n","import matplotlib.pyplot as plt\n","%matplotlib inline \n","from IPython.display import set_matplotlib_formats\n","set_matplotlib_formats('svg', 'pdf') # For export\n","from matplotlib.colors import to_rgba\n","import seaborn as sns\n","sns.set()\n","\n","def visualize_samples(data, label):\n","    if isinstance(data, torch.Tensor):\n","        data = data.cpu().numpy()\n","    if isinstance(label, torch.Tensor):\n","        label = label.cpu().numpy()\n","    data_0 = data[label == 0]\n","    data_1 = data[label == 1]\n","    \n","    plt.figure(figsize=(4,4))\n","    plt.scatter(data_0[:,0], data_0[:,1], edgecolor=\"#333\", label=\"Class 0\")\n","    plt.scatter(data_1[:,0], data_1[:,1], edgecolor=\"#333\", label=\"Class 1\")\n","    plt.title(\"Dataset samples\")\n","    plt.ylabel(r\"$x_2$\")\n","    plt.xlabel(r\"$x_1$\")\n","    plt.legend()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":404},"executionInfo":{"elapsed":2361,"status":"ok","timestamp":1681658783424,"user":{"displayName":"Dr CAO Yixin _","userId":"02213333189428679281"},"user_tz":-480},"id":"boDVjaJziSad","outputId":"6c531ca9-4dfd-414a-ab03-4248718e3b58"},"outputs":[{"data":{"application/pdf":"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\n","image/svg+xml":["<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n","<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n","  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n","<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"289.424844pt\" height=\"287.037813pt\" viewBox=\"0 0 289.424844 287.037813\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n"," <metadata>\n","  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n","   <cc:Work>\n","    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n","    <dc:date>2023-04-16T15:26:21.169643</dc:date>\n","    <dc:format>image/svg+xml</dc:format>\n","    <dc:creator>\n","     <cc:Agent>\n","      <dc:title>Matplotlib v3.7.1, https://matplotlib.org/</dc:title>\n","     </cc:Agent>\n","    </dc:creator>\n","   </cc:Work>\n","  </rdf:RDF>\n"," </metadata>\n"," <defs>\n","  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n"," </defs>\n"," <g id=\"figure_1\">\n","  <g id=\"patch_1\">\n","   <path d=\"M 0 287.037813 \n","L 289.424844 287.037813 \n","L 289.424844 0 \n","L 0 0 \n","z\n","\" style=\"fill: #ffffff\"/>\n","  </g>\n","  <g id=\"axes_1\">\n","   <g id=\"patch_2\">\n","    <path d=\"M 59.024844 244.078125 \n","L 282.224844 244.078125 \n","L 282.224844 22.318125 \n","L 59.024844 22.318125 \n","z\n","\" style=\"fill: #eaeaf2\"/>\n","   </g>\n","   <g id=\"matplotlib.axis_1\">\n","    <g id=\"xtick_1\">\n","     <g id=\"line2d_1\">\n","      <path d=\"M 97.371639 244.078125 \n","L 97.371639 22.318125 \n","\" clip-path=\"url(#pa3c92064d6)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n","     </g>\n","     <g id=\"text_1\">\n","      <!-- 0.0 -->\n","      <g style=\"fill: #262626\" transform=\"translate(88.62492 261.936406) scale(0.11 -0.11)\">\n","       <defs>\n","        <path id=\"DejaVuSans-30\" d=\"M 2034 4250 \n","Q 1547 4250 1301 3770 \n","Q 1056 3291 1056 2328 \n","Q 1056 1369 1301 889 \n","Q 1547 409 2034 409 \n","Q 2525 409 2770 889 \n","Q 3016 1369 3016 2328 \n","Q 3016 3291 2770 3770 \n","Q 2525 4250 2034 4250 \n","z\n","M 2034 4750 \n","Q 2819 4750 3233 4129 \n","Q 3647 3509 3647 2328 \n","Q 3647 1150 3233 529 \n","Q 2819 -91 2034 -91 \n","Q 1250 -91 836 529 \n","Q 422 1150 422 2328 \n","Q 422 3509 836 4129 \n","Q 1250 4750 2034 4750 \n","z\n","\" transform=\"scale(0.015625)\"/>\n","        <path id=\"DejaVuSans-2e\" d=\"M 684 794 \n","L 1344 794 \n","L 1344 0 \n","L 684 0 \n","L 684 794 \n","z\n","\" transform=\"scale(0.015625)\"/>\n","       </defs>\n","       <use xlink:href=\"#DejaVuSans-30\"/>\n","       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n","       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n","      </g>\n","     </g>\n","    </g>\n","    <g id=\"xtick_2\">\n","     <g id=\"line2d_2\">\n","      <path d=\"M 165.436225 244.078125 \n","L 165.436225 22.318125 \n","\" clip-path=\"url(#pa3c92064d6)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n","     </g>\n","     <g id=\"text_2\">\n","      <!-- 0.5 -->\n","      <g style=\"fill: #262626\" transform=\"translate(156.689507 261.936406) scale(0.11 -0.11)\">\n","       <defs>\n","        <path id=\"DejaVuSans-35\" d=\"M 691 4666 \n","L 3169 4666 \n","L 3169 4134 \n","L 1269 4134 \n","L 1269 2991 \n","Q 1406 3038 1543 3061 \n","Q 1681 3084 1819 3084 \n","Q 2600 3084 3056 2656 \n","Q 3513 2228 3513 1497 \n","Q 3513 744 3044 326 \n","Q 2575 -91 1722 -91 \n","Q 1428 -91 1123 -41 \n","Q 819 9 494 109 \n","L 494 744 \n","Q 775 591 1075 516 \n","Q 1375 441 1709 441 \n","Q 2250 441 2565 725 \n","Q 2881 1009 2881 1497 \n","Q 2881 1984 2565 2268 \n","Q 2250 2553 1709 2553 \n","Q 1456 2553 1204 2497 \n","Q 953 2441 691 2322 \n","L 691 4666 \n","z\n","\" transform=\"scale(0.015625)\"/>\n","       </defs>\n","       <use xlink:href=\"#DejaVuSans-30\"/>\n","       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n","       <use xlink:href=\"#DejaVuSans-35\" x=\"95.410156\"/>\n","      </g>\n","     </g>\n","    </g>\n","    <g id=\"xtick_3\">\n","     <g id=\"line2d_3\">\n","      <path d=\"M 233.500812 244.078125 \n","L 233.500812 22.318125 \n","\" clip-path=\"url(#pa3c92064d6)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n","     </g>\n","     <g id=\"text_3\">\n","      <!-- 1.0 -->\n","      <g style=\"fill: #262626\" transform=\"translate(224.754093 261.936406) scale(0.11 -0.11)\">\n","       <defs>\n","        <path id=\"DejaVuSans-31\" d=\"M 794 531 \n","L 1825 531 \n","L 1825 4091 \n","L 703 3866 \n","L 703 4441 \n","L 1819 4666 \n","L 2450 4666 \n","L 2450 531 \n","L 3481 531 \n","L 3481 0 \n","L 794 0 \n","L 794 531 \n","z\n","\" transform=\"scale(0.015625)\"/>\n","       </defs>\n","       <use xlink:href=\"#DejaVuSans-31\"/>\n","       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n","       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n","      </g>\n","     </g>\n","    </g>\n","    <g id=\"text_4\">\n","     <!-- $x_1$ -->\n","     <g style=\"fill: #262626\" transform=\"translate(164.204844 277.342188) scale(0.12 -0.12)\">\n","      <defs>\n","       <path id=\"DejaVuSans-Oblique-78\" d=\"M 3841 3500 \n","L 2234 1784 \n","L 3219 0 \n","L 2559 0 \n","L 1819 1388 \n","L 531 0 \n","L -166 0 \n","L 1556 1844 \n","L 641 3500 \n","L 1300 3500 \n","L 1972 2234 \n","L 3144 3500 \n","L 3841 3500 \n","z\n","\" transform=\"scale(0.015625)\"/>\n","      </defs>\n","      <use xlink:href=\"#DejaVuSans-Oblique-78\" transform=\"translate(0 0.3125)\"/>\n","      <use xlink:href=\"#DejaVuSans-31\" transform=\"translate(59.179688 -16.09375) scale(0.7)\"/>\n","     </g>\n","    </g>\n","   </g>\n","   <g id=\"matplotlib.axis_2\">\n","    <g id=\"ytick_1\">\n","     <g id=\"line2d_4\">\n","      <path d=\"M 59.024844 219.458293 \n","L 282.224844 219.458293 \n","\" clip-path=\"url(#pa3c92064d6)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n","     </g>\n","     <g id=\"text_5\">\n","      <!-- −0.2 -->\n","      <g style=\"fill: #262626\" transform=\"translate(22.81375 223.637434) scale(0.11 -0.11)\">\n","       <defs>\n","        <path id=\"DejaVuSans-2212\" d=\"M 678 2272 \n","L 4684 2272 \n","L 4684 1741 \n","L 678 1741 \n","L 678 2272 \n","z\n","\" transform=\"scale(0.015625)\"/>\n","        <path id=\"DejaVuSans-32\" d=\"M 1228 531 \n","L 3431 531 \n","L 3431 0 \n","L 469 0 \n","L 469 531 \n","Q 828 903 1448 1529 \n","Q 2069 2156 2228 2338 \n","Q 2531 2678 2651 2914 \n","Q 2772 3150 2772 3378 \n","Q 2772 3750 2511 3984 \n","Q 2250 4219 1831 4219 \n","Q 1534 4219 1204 4116 \n","Q 875 4013 500 3803 \n","L 500 4441 \n","Q 881 4594 1212 4672 \n","Q 1544 4750 1819 4750 \n","Q 2544 4750 2975 4387 \n","Q 3406 4025 3406 3419 \n","Q 3406 3131 3298 2873 \n","Q 3191 2616 2906 2266 \n","Q 2828 2175 2409 1742 \n","Q 1991 1309 1228 531 \n","z\n","\" transform=\"scale(0.015625)\"/>\n","       </defs>\n","       <use xlink:href=\"#DejaVuSans-2212\"/>\n","       <use xlink:href=\"#DejaVuSans-30\" x=\"83.789062\"/>\n","       <use xlink:href=\"#DejaVuSans-2e\" x=\"147.412109\"/>\n","       <use xlink:href=\"#DejaVuSans-32\" x=\"179.199219\"/>\n","      </g>\n","     </g>\n","    </g>\n","    <g id=\"ytick_2\">\n","     <g id=\"line2d_5\">\n","      <path d=\"M 59.024844 193.060777 \n","L 282.224844 193.060777 \n","\" clip-path=\"url(#pa3c92064d6)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n","     </g>\n","     <g id=\"text_6\">\n","      <!-- 0.0 -->\n","      <g style=\"fill: #262626\" transform=\"translate(32.031406 197.239918) scale(0.11 -0.11)\">\n","       <use xlink:href=\"#DejaVuSans-30\"/>\n","       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n","       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n","      </g>\n","     </g>\n","    </g>\n","    <g id=\"ytick_3\">\n","     <g id=\"line2d_6\">\n","      <path d=\"M 59.024844 166.663261 \n","L 282.224844 166.663261 \n","\" clip-path=\"url(#pa3c92064d6)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n","     </g>\n","     <g id=\"text_7\">\n","      <!-- 0.2 -->\n","      <g style=\"fill: #262626\" transform=\"translate(32.031406 170.842401) scale(0.11 -0.11)\">\n","       <use xlink:href=\"#DejaVuSans-30\"/>\n","       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n","       <use xlink:href=\"#DejaVuSans-32\" x=\"95.410156\"/>\n","      </g>\n","     </g>\n","    </g>\n","    <g id=\"ytick_4\">\n","     <g id=\"line2d_7\">\n","      <path d=\"M 59.024844 140.265745 \n","L 282.224844 140.265745 \n","\" clip-path=\"url(#pa3c92064d6)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n","     </g>\n","     <g id=\"text_8\">\n","      <!-- 0.4 -->\n","      <g style=\"fill: #262626\" transform=\"translate(32.031406 144.444885) scale(0.11 -0.11)\">\n","       <defs>\n","        <path id=\"DejaVuSans-34\" d=\"M 2419 4116 \n","L 825 1625 \n","L 2419 1625 \n","L 2419 4116 \n","z\n","M 2253 4666 \n","L 3047 4666 \n","L 3047 1625 \n","L 3713 1625 \n","L 3713 1100 \n","L 3047 1100 \n","L 3047 0 \n","L 2419 0 \n","L 2419 1100 \n","L 313 1100 \n","L 313 1709 \n","L 2253 4666 \n","z\n","\" transform=\"scale(0.015625)\"/>\n","       </defs>\n","       <use xlink:href=\"#DejaVuSans-30\"/>\n","       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n","       <use xlink:href=\"#DejaVuSans-34\" x=\"95.410156\"/>\n","      </g>\n","     </g>\n","    </g>\n","    <g id=\"ytick_5\">\n","     <g id=\"line2d_8\">\n","      <path d=\"M 59.024844 113.868229 \n","L 282.224844 113.868229 \n","\" clip-path=\"url(#pa3c92064d6)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n","     </g>\n","     <g id=\"text_9\">\n","      <!-- 0.6 -->\n","      <g style=\"fill: #262626\" transform=\"translate(32.031406 118.047369) scale(0.11 -0.11)\">\n","       <defs>\n","        <path id=\"DejaVuSans-36\" d=\"M 2113 2584 \n","Q 1688 2584 1439 2293 \n","Q 1191 2003 1191 1497 \n","Q 1191 994 1439 701 \n","Q 1688 409 2113 409 \n","Q 2538 409 2786 701 \n","Q 3034 994 3034 1497 \n","Q 3034 2003 2786 2293 \n","Q 2538 2584 2113 2584 \n","z\n","M 3366 4563 \n","L 3366 3988 \n","Q 3128 4100 2886 4159 \n","Q 2644 4219 2406 4219 \n","Q 1781 4219 1451 3797 \n","Q 1122 3375 1075 2522 \n","Q 1259 2794 1537 2939 \n","Q 1816 3084 2150 3084 \n","Q 2853 3084 3261 2657 \n","Q 3669 2231 3669 1497 \n","Q 3669 778 3244 343 \n","Q 2819 -91 2113 -91 \n","Q 1303 -91 875 529 \n","Q 447 1150 447 2328 \n","Q 447 3434 972 4092 \n","Q 1497 4750 2381 4750 \n","Q 2619 4750 2861 4703 \n","Q 3103 4656 3366 4563 \n","z\n","\" transform=\"scale(0.015625)\"/>\n","       </defs>\n","       <use xlink:href=\"#DejaVuSans-30\"/>\n","       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n","       <use xlink:href=\"#DejaVuSans-36\" x=\"95.410156\"/>\n","      </g>\n","     </g>\n","    </g>\n","    <g id=\"ytick_6\">\n","     <g id=\"line2d_9\">\n","      <path d=\"M 59.024844 87.470713 \n","L 282.224844 87.470713 \n","\" clip-path=\"url(#pa3c92064d6)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n","     </g>\n","     <g id=\"text_10\">\n","      <!-- 0.8 -->\n","      <g style=\"fill: #262626\" transform=\"translate(32.031406 91.649853) scale(0.11 -0.11)\">\n","       <defs>\n","        <path id=\"DejaVuSans-38\" d=\"M 2034 2216 \n","Q 1584 2216 1326 1975 \n","Q 1069 1734 1069 1313 \n","Q 1069 891 1326 650 \n","Q 1584 409 2034 409 \n","Q 2484 409 2743 651 \n","Q 3003 894 3003 1313 \n","Q 3003 1734 2745 1975 \n","Q 2488 2216 2034 2216 \n","z\n","M 1403 2484 \n","Q 997 2584 770 2862 \n","Q 544 3141 544 3541 \n","Q 544 4100 942 4425 \n","Q 1341 4750 2034 4750 \n","Q 2731 4750 3128 4425 \n","Q 3525 4100 3525 3541 \n","Q 3525 3141 3298 2862 \n","Q 3072 2584 2669 2484 \n","Q 3125 2378 3379 2068 \n","Q 3634 1759 3634 1313 \n","Q 3634 634 3220 271 \n","Q 2806 -91 2034 -91 \n","Q 1263 -91 848 271 \n","Q 434 634 434 1313 \n","Q 434 1759 690 2068 \n","Q 947 2378 1403 2484 \n","z\n","M 1172 3481 \n","Q 1172 3119 1398 2916 \n","Q 1625 2713 2034 2713 \n","Q 2441 2713 2670 2916 \n","Q 2900 3119 2900 3481 \n","Q 2900 3844 2670 4047 \n","Q 2441 4250 2034 4250 \n","Q 1625 4250 1398 4047 \n","Q 1172 3844 1172 3481 \n","z\n","\" transform=\"scale(0.015625)\"/>\n","       </defs>\n","       <use xlink:href=\"#DejaVuSans-30\"/>\n","       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n","       <use xlink:href=\"#DejaVuSans-38\" x=\"95.410156\"/>\n","      </g>\n","     </g>\n","    </g>\n","    <g id=\"ytick_7\">\n","     <g id=\"line2d_10\">\n","      <path d=\"M 59.024844 61.073196 \n","L 282.224844 61.073196 \n","\" clip-path=\"url(#pa3c92064d6)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n","     </g>\n","     <g id=\"text_11\">\n","      <!-- 1.0 -->\n","      <g style=\"fill: #262626\" transform=\"translate(32.031406 65.252337) scale(0.11 -0.11)\">\n","       <use xlink:href=\"#DejaVuSans-31\"/>\n","       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n","       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n","      </g>\n","     </g>\n","    </g>\n","    <g id=\"ytick_8\">\n","     <g id=\"line2d_11\">\n","      <path d=\"M 59.024844 34.67568 \n","L 282.224844 34.67568 \n","\" clip-path=\"url(#pa3c92064d6)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n","     </g>\n","     <g id=\"text_12\">\n","      <!-- 1.2 -->\n","      <g style=\"fill: #262626\" transform=\"translate(32.031406 38.854821) scale(0.11 -0.11)\">\n","       <use xlink:href=\"#DejaVuSans-31\"/>\n","       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n","       <use xlink:href=\"#DejaVuSans-32\" x=\"95.410156\"/>\n","      </g>\n","     </g>\n","    </g>\n","    <g id=\"text_13\">\n","     <!-- $x_2$ -->\n","     <g style=\"fill: #262626\" transform=\"translate(16.318125 139.618125) rotate(-90) scale(0.12 -0.12)\">\n","      <use xlink:href=\"#DejaVuSans-Oblique-78\" transform=\"translate(0 0.3125)\"/>\n","      <use xlink:href=\"#DejaVuSans-32\" transform=\"translate(59.179688 -16.09375) scale(0.7)\"/>\n","     </g>\n","    </g>\n","   </g>\n","   <g id=\"PathCollection_1\">\n","    <defs>\n","     <path id=\"mb6a8ea5cf4\" d=\"M 0 3 \n","C 0.795609 3 1.55874 2.683901 2.12132 2.12132 \n","C 2.683901 1.55874 3 0.795609 3 0 \n","C 3 -0.795609 2.683901 -1.55874 2.12132 -2.12132 \n","C 1.55874 -2.683901 0.795609 -3 0 -3 \n","C -0.795609 -3 -1.55874 -2.683901 -2.12132 -2.12132 \n","C -2.683901 -1.55874 -3 -0.795609 -3 0 \n","C -3 0.795609 -2.683901 1.55874 -2.12132 2.12132 \n","C -1.55874 2.683901 -0.795609 3 0 3 \n","z\n","\" style=\"stroke: #333333\"/>\n","    </defs>\n","    <g clip-path=\"url(#pa3c92064d6)\">\n","     <use xlink:href=\"#mb6a8ea5cf4\" x=\"214.662106\" y=\"54.647104\" style=\"fill: #4c72b0; stroke: #333333\"/>\n","     <use xlink:href=\"#mb6a8ea5cf4\" x=\"90.796318\" y=\"191.565385\" style=\"fill: #4c72b0; stroke: #333333\"/>\n","     <use xlink:href=\"#mb6a8ea5cf4\" x=\"98.421887\" y=\"205.240761\" style=\"fill: #4c72b0; stroke: #333333\"/>\n","     <use xlink:href=\"#mb6a8ea5cf4\" x=\"116.693511\" y=\"191.055486\" style=\"fill: #4c72b0; stroke: #333333\"/>\n","     <use xlink:href=\"#mb6a8ea5cf4\" x=\"235.706925\" y=\"45.288041\" style=\"fill: #4c72b0; stroke: #333333\"/>\n","     <use xlink:href=\"#mb6a8ea5cf4\" x=\"226.918296\" y=\"68.225436\" style=\"fill: #4c72b0; stroke: #333333\"/>\n","     <use xlink:href=\"#mb6a8ea5cf4\" x=\"272.079389\" y=\"35.289762\" style=\"fill: #4c72b0; stroke: #333333\"/>\n","     <use xlink:href=\"#mb6a8ea5cf4\" x=\"90.454978\" y=\"201.22408\" style=\"fill: #4c72b0; stroke: #333333\"/>\n","     <use xlink:href=\"#mb6a8ea5cf4\" x=\"227.370834\" y=\"62.03626\" style=\"fill: #4c72b0; stroke: #333333\"/>\n","     <use xlink:href=\"#mb6a8ea5cf4\" x=\"226.041545\" y=\"76.153478\" style=\"fill: #4c72b0; stroke: #333333\"/>\n","     <use xlink:href=\"#mb6a8ea5cf4\" x=\"227.391987\" y=\"61.475157\" style=\"fill: #4c72b0; stroke: #333333\"/>\n","     <use xlink:href=\"#mb6a8ea5cf4\" x=\"220.423143\" y=\"50.099857\" style=\"fill: #4c72b0; stroke: #333333\"/>\n","     <use xlink:href=\"#mb6a8ea5cf4\" x=\"249.563263\" y=\"65.447635\" style=\"fill: #4c72b0; stroke: #333333\"/>\n","     <use xlink:href=\"#mb6a8ea5cf4\" x=\"225.764552\" y=\"72.294176\" style=\"fill: #4c72b0; stroke: #333333\"/>\n","     <use xlink:href=\"#mb6a8ea5cf4\" x=\"220.380017\" y=\"94.951691\" style=\"fill: #4c72b0; stroke: #333333\"/>\n","     <use xlink:href=\"#mb6a8ea5cf4\" x=\"243.160706\" y=\"50.252289\" style=\"fill: #4c72b0; stroke: #333333\"/>\n","     <use xlink:href=\"#mb6a8ea5cf4\" x=\"214.935927\" y=\"58.526389\" style=\"fill: #4c72b0; stroke: #333333\"/>\n","     <use xlink:href=\"#mb6a8ea5cf4\" x=\"251.794545\" y=\"78.129042\" style=\"fill: #4c72b0; stroke: #333333\"/>\n","     <use xlink:href=\"#mb6a8ea5cf4\" x=\"102.181301\" y=\"228.004332\" style=\"fill: #4c72b0; stroke: #333333\"/>\n","     <use xlink:href=\"#mb6a8ea5cf4\" x=\"79.44162\" y=\"190.97291\" style=\"fill: #4c72b0; stroke: #333333\"/>\n","     <use xlink:href=\"#mb6a8ea5cf4\" x=\"100.829743\" y=\"195.424136\" style=\"fill: #4c72b0; stroke: #333333\"/>\n","     <use xlink:href=\"#mb6a8ea5cf4\" x=\"113.697398\" y=\"198.725911\" style=\"fill: #4c72b0; stroke: #333333\"/>\n","     <use xlink:href=\"#mb6a8ea5cf4\" x=\"223.188314\" y=\"62.071386\" style=\"fill: #4c72b0; stroke: #333333\"/>\n","     <use xlink:href=\"#mb6a8ea5cf4\" x=\"78.778915\" y=\"178.38711\" style=\"fill: #4c72b0; stroke: #333333\"/>\n","     <use xlink:href=\"#mb6a8ea5cf4\" x=\"106.104348\" y=\"210.632942\" style=\"fill: #4c72b0; stroke: #333333\"/>\n","     <use xlink:href=\"#mb6a8ea5cf4\" x=\"124.693961\" y=\"209.600167\" style=\"fill: #4c72b0; stroke: #333333\"/>\n","     <use xlink:href=\"#mb6a8ea5cf4\" x=\"122.68483\" y=\"158.451694\" style=\"fill: #4c72b0; stroke: #333333\"/>\n","     <use xlink:href=\"#mb6a8ea5cf4\" x=\"238.524698\" y=\"56.053752\" style=\"fill: #4c72b0; stroke: #333333\"/>\n","     <use xlink:href=\"#mb6a8ea5cf4\" x=\"205.340603\" y=\"49.609172\" style=\"fill: #4c72b0; stroke: #333333\"/>\n","     <use xlink:href=\"#mb6a8ea5cf4\" x=\"86.437536\" y=\"207.855272\" style=\"fill: #4c72b0; stroke: #333333\"/>\n","     <use xlink:href=\"#mb6a8ea5cf4\" x=\"100.034879\" y=\"203.375846\" style=\"fill: #4c72b0; stroke: #333333\"/>\n","     <use xlink:href=\"#mb6a8ea5cf4\" x=\"73.006163\" y=\"196.513223\" style=\"fill: #4c72b0; stroke: #333333\"/>\n","     <use xlink:href=\"#mb6a8ea5cf4\" x=\"90.836117\" y=\"210.049868\" style=\"fill: #4c72b0; stroke: #333333\"/>\n","     <use xlink:href=\"#mb6a8ea5cf4\" x=\"109.577911\" y=\"221.857279\" style=\"fill: #4c72b0; stroke: #333333\"/>\n","     <use xlink:href=\"#mb6a8ea5cf4\" x=\"98.205792\" y=\"191.935437\" style=\"fill: #4c72b0; stroke: #333333\"/>\n","     <use xlink:href=\"#mb6a8ea5cf4\" x=\"221.132706\" y=\"56.942039\" style=\"fill: #4c72b0; stroke: #333333\"/>\n","     <use xlink:href=\"#mb6a8ea5cf4\" x=\"80.33584\" y=\"204.026392\" style=\"fill: #4c72b0; stroke: #333333\"/>\n","     <use xlink:href=\"#mb6a8ea5cf4\" x=\"99.102019\" y=\"187.248492\" style=\"fill: #4c72b0; stroke: #333333\"/>\n","     <use xlink:href=\"#mb6a8ea5cf4\" x=\"229.672838\" y=\"74.766734\" style=\"fill: #4c72b0; stroke: #333333\"/>\n","     <use xlink:href=\"#mb6a8ea5cf4\" x=\"84.842432\" y=\"184.268887\" style=\"fill: #4c72b0; stroke: #333333\"/>\n","     <use xlink:href=\"#mb6a8ea5cf4\" x=\"91.378349\" y=\"223.654924\" style=\"fill: #4c72b0; stroke: #333333\"/>\n","     <use xlink:href=\"#mb6a8ea5cf4\" x=\"89.636815\" y=\"194.206369\" style=\"fill: #4c72b0; stroke: #333333\"/>\n","     <use xlink:href=\"#mb6a8ea5cf4\" x=\"103.23943\" y=\"188.198974\" style=\"fill: #4c72b0; stroke: #333333\"/>\n","     <use xlink:href=\"#mb6a8ea5cf4\" x=\"236.281277\" y=\"61.422652\" style=\"fill: #4c72b0; stroke: #333333\"/>\n","     <use xlink:href=\"#mb6a8ea5cf4\" x=\"227.867975\" y=\"54.230841\" style=\"fill: #4c72b0; stroke: #333333\"/>\n","     <use xlink:href=\"#mb6a8ea5cf4\" x=\"99.297554\" y=\"192.122297\" style=\"fill: #4c72b0; stroke: #333333\"/>\n","     <use xlink:href=\"#mb6a8ea5cf4\" x=\"238.51329\" y=\"51.768479\" style=\"fill: #4c72b0; stroke: #333333\"/>\n","     <use xlink:href=\"#mb6a8ea5cf4\" x=\"218.746975\" y=\"66.20654\" style=\"fill: #4c72b0; stroke: #333333\"/>\n","     <use xlink:href=\"#mb6a8ea5cf4\" x=\"244.56281\" y=\"41.299891\" style=\"fill: #4c72b0; stroke: #333333\"/>\n","     <use xlink:href=\"#mb6a8ea5cf4\" x=\"234.09837\" y=\"42.009926\" style=\"fill: #4c72b0; stroke: #333333\"/>\n","     <use xlink:href=\"#mb6a8ea5cf4\" x=\"93.20335\" y=\"185.224229\" style=\"fill: #4c72b0; stroke: #333333\"/>\n","     <use xlink:href=\"#mb6a8ea5cf4\" x=\"103.575317\" y=\"189.756728\" style=\"fill: #4c72b0; stroke: #333333\"/>\n","     <use xlink:href=\"#mb6a8ea5cf4\" x=\"115.785741\" y=\"190.945305\" style=\"fill: #4c72b0; stroke: #333333\"/>\n","     <use xlink:href=\"#mb6a8ea5cf4\" x=\"98.368119\" y=\"220.715432\" style=\"fill: #4c72b0; stroke: #333333\"/>\n","     <use xlink:href=\"#mb6a8ea5cf4\" x=\"219.66118\" y=\"61.174509\" style=\"fill: #4c72b0; stroke: #333333\"/>\n","     <use xlink:href=\"#mb6a8ea5cf4\" x=\"90.317141\" y=\"181.979857\" style=\"fill: #4c72b0; stroke: #333333\"/>\n","     <use xlink:href=\"#mb6a8ea5cf4\" x=\"247.273593\" y=\"79.657032\" style=\"fill: #4c72b0; stroke: #333333\"/>\n","     <use xlink:href=\"#mb6a8ea5cf4\" x=\"262.491222\" y=\"81.110851\" style=\"fill: #4c72b0; stroke: #333333\"/>\n","     <use xlink:href=\"#mb6a8ea5cf4\" x=\"195.471369\" y=\"70.459551\" style=\"fill: #4c72b0; stroke: #333333\"/>\n","     <use xlink:href=\"#mb6a8ea5cf4\" x=\"93.261158\" y=\"190.147908\" style=\"fill: #4c72b0; stroke: #333333\"/>\n","     <use xlink:href=\"#mb6a8ea5cf4\" x=\"101.089369\" y=\"157.011918\" style=\"fill: #4c72b0; stroke: #333333\"/>\n","     <use xlink:href=\"#mb6a8ea5cf4\" x=\"230.599319\" y=\"72.793994\" style=\"fill: #4c72b0; stroke: #333333\"/>\n","     <use xlink:href=\"#mb6a8ea5cf4\" x=\"80.328927\" y=\"153.133891\" style=\"fill: #4c72b0; stroke: #333333\"/>\n","     <use xlink:href=\"#mb6a8ea5cf4\" x=\"254.232733\" y=\"44.172317\" style=\"fill: #4c72b0; stroke: #333333\"/>\n","     <use xlink:href=\"#mb6a8ea5cf4\" x=\"231.919528\" y=\"42.983822\" style=\"fill: #4c72b0; stroke: #333333\"/>\n","     <use xlink:href=\"#mb6a8ea5cf4\" x=\"92.612844\" y=\"188.048564\" style=\"fill: #4c72b0; stroke: #333333\"/>\n","     <use xlink:href=\"#mb6a8ea5cf4\" x=\"244.786397\" y=\"33.459692\" style=\"fill: #4c72b0; stroke: #333333\"/>\n","     <use xlink:href=\"#mb6a8ea5cf4\" x=\"244.327295\" y=\"57.386985\" style=\"fill: #4c72b0; stroke: #333333\"/>\n","     <use xlink:href=\"#mb6a8ea5cf4\" x=\"86.593641\" y=\"186.854536\" style=\"fill: #4c72b0; stroke: #333333\"/>\n","     <use xlink:href=\"#mb6a8ea5cf4\" x=\"234.734665\" y=\"38.077585\" style=\"fill: #4c72b0; stroke: #333333\"/>\n","     <use xlink:href=\"#mb6a8ea5cf4\" x=\"80.137668\" y=\"187.924338\" style=\"fill: #4c72b0; stroke: #333333\"/>\n","     <use xlink:href=\"#mb6a8ea5cf4\" x=\"221.597756\" y=\"32.398125\" style=\"fill: #4c72b0; stroke: #333333\"/>\n","     <use xlink:href=\"#mb6a8ea5cf4\" x=\"100.437745\" y=\"194.08032\" style=\"fill: #4c72b0; stroke: #333333\"/>\n","     <use xlink:href=\"#mb6a8ea5cf4\" x=\"246.918982\" y=\"44.200748\" style=\"fill: #4c72b0; stroke: #333333\"/>\n","     <use xlink:href=\"#mb6a8ea5cf4\" x=\"103.620185\" y=\"186.053123\" style=\"fill: #4c72b0; stroke: #333333\"/>\n","     <use xlink:href=\"#mb6a8ea5cf4\" x=\"249.591889\" y=\"56.770049\" style=\"fill: #4c72b0; stroke: #333333\"/>\n","     <use xlink:href=\"#mb6a8ea5cf4\" x=\"113.846835\" y=\"194.817589\" style=\"fill: #4c72b0; stroke: #333333\"/>\n","     <use xlink:href=\"#mb6a8ea5cf4\" x=\"98.319839\" y=\"214.224113\" style=\"fill: #4c72b0; stroke: #333333\"/>\n","     <use xlink:href=\"#mb6a8ea5cf4\" x=\"216.357122\" y=\"63.885455\" style=\"fill: #4c72b0; stroke: #333333\"/>\n","     <use xlink:href=\"#mb6a8ea5cf4\" x=\"102.059426\" y=\"233.998125\" style=\"fill: #4c72b0; stroke: #333333\"/>\n","     <use xlink:href=\"#mb6a8ea5cf4\" x=\"213.643345\" y=\"79.971518\" style=\"fill: #4c72b0; stroke: #333333\"/>\n","     <use xlink:href=\"#mb6a8ea5cf4\" x=\"225.236043\" y=\"64.501415\" style=\"fill: #4c72b0; stroke: #333333\"/>\n","     <use xlink:href=\"#mb6a8ea5cf4\" x=\"229.655011\" y=\"50.919811\" style=\"fill: #4c72b0; stroke: #333333\"/>\n","     <use xlink:href=\"#mb6a8ea5cf4\" x=\"107.511102\" y=\"175.302046\" style=\"fill: #4c72b0; stroke: #333333\"/>\n","     <use xlink:href=\"#mb6a8ea5cf4\" x=\"99.098055\" y=\"225.425079\" style=\"fill: #4c72b0; stroke: #333333\"/>\n","     <use xlink:href=\"#mb6a8ea5cf4\" x=\"116.355452\" y=\"210.225837\" style=\"fill: #4c72b0; stroke: #333333\"/>\n","     <use xlink:href=\"#mb6a8ea5cf4\" x=\"223.499808\" y=\"60.48378\" style=\"fill: #4c72b0; stroke: #333333\"/>\n","     <use xlink:href=\"#mb6a8ea5cf4\" x=\"243.576789\" y=\"42.381126\" style=\"fill: #4c72b0; stroke: #333333\"/>\n","     <use xlink:href=\"#mb6a8ea5cf4\" x=\"246.042385\" y=\"54.101019\" style=\"fill: #4c72b0; stroke: #333333\"/>\n","     <use xlink:href=\"#mb6a8ea5cf4\" x=\"97.259626\" y=\"212.19016\" style=\"fill: #4c72b0; stroke: #333333\"/>\n","     <use xlink:href=\"#mb6a8ea5cf4\" x=\"225.26251\" y=\"63.439006\" style=\"fill: #4c72b0; stroke: #333333\"/>\n","     <use xlink:href=\"#mb6a8ea5cf4\" x=\"229.900498\" y=\"100.45275\" style=\"fill: #4c72b0; stroke: #333333\"/>\n","     <use xlink:href=\"#mb6a8ea5cf4\" x=\"227.856907\" y=\"41.857525\" style=\"fill: #4c72b0; stroke: #333333\"/>\n","     <use xlink:href=\"#mb6a8ea5cf4\" x=\"102.372053\" y=\"193.314574\" style=\"fill: #4c72b0; stroke: #333333\"/>\n","     <use xlink:href=\"#mb6a8ea5cf4\" x=\"237.548105\" y=\"55.338887\" style=\"fill: #4c72b0; stroke: #333333\"/>\n","     <use xlink:href=\"#mb6a8ea5cf4\" x=\"233.547012\" y=\"74.588914\" style=\"fill: #4c72b0; stroke: #333333\"/>\n","     <use xlink:href=\"#mb6a8ea5cf4\" x=\"238.150808\" y=\"40.105779\" style=\"fill: #4c72b0; stroke: #333333\"/>\n","     <use xlink:href=\"#mb6a8ea5cf4\" x=\"228.751566\" y=\"67.117162\" style=\"fill: #4c72b0; stroke: #333333\"/>\n","     <use xlink:href=\"#mb6a8ea5cf4\" x=\"82.006913\" y=\"178.222562\" style=\"fill: #4c72b0; stroke: #333333\"/>\n","    </g>\n","   </g>\n","   <g id=\"PathCollection_2\">\n","    <defs>\n","     <path id=\"m9aca37a79c\" d=\"M 0 3 \n","C 0.795609 3 1.55874 2.683901 2.12132 2.12132 \n","C 2.683901 1.55874 3 0.795609 3 0 \n","C 3 -0.795609 2.683901 -1.55874 2.12132 -2.12132 \n","C 1.55874 -2.683901 0.795609 -3 0 -3 \n","C -0.795609 -3 -1.55874 -2.683901 -2.12132 -2.12132 \n","C -2.683901 -1.55874 -3 -0.795609 -3 0 \n","C -3 0.795609 -2.683901 1.55874 -2.12132 2.12132 \n","C -1.55874 2.683901 -0.795609 3 0 3 \n","z\n","\" style=\"stroke: #333333\"/>\n","    </defs>\n","    <g clip-path=\"url(#pa3c92064d6)\">\n","     <use xlink:href=\"#m9aca37a79c\" x=\"228.57951\" y=\"215.388637\" style=\"fill: #dd8452; stroke: #333333\"/>\n","     <use xlink:href=\"#m9aca37a79c\" x=\"83.731091\" y=\"60.63832\" style=\"fill: #dd8452; stroke: #333333\"/>\n","     <use xlink:href=\"#m9aca37a79c\" x=\"91.52903\" y=\"74.031713\" style=\"fill: #dd8452; stroke: #333333\"/>\n","     <use xlink:href=\"#m9aca37a79c\" x=\"91.927756\" y=\"78.616116\" style=\"fill: #dd8452; stroke: #333333\"/>\n","     <use xlink:href=\"#m9aca37a79c\" x=\"255.164342\" y=\"194.655362\" style=\"fill: #dd8452; stroke: #333333\"/>\n","     <use xlink:href=\"#m9aca37a79c\" x=\"112.300125\" y=\"70.097099\" style=\"fill: #dd8452; stroke: #333333\"/>\n","     <use xlink:href=\"#m9aca37a79c\" x=\"234.399852\" y=\"193.07099\" style=\"fill: #dd8452; stroke: #333333\"/>\n","     <use xlink:href=\"#m9aca37a79c\" x=\"82.945756\" y=\"57.037939\" style=\"fill: #dd8452; stroke: #333333\"/>\n","     <use xlink:href=\"#m9aca37a79c\" x=\"103.021791\" y=\"70.542178\" style=\"fill: #dd8452; stroke: #333333\"/>\n","     <use xlink:href=\"#m9aca37a79c\" x=\"98.200055\" y=\"76.613922\" style=\"fill: #dd8452; stroke: #333333\"/>\n","     <use xlink:href=\"#m9aca37a79c\" x=\"119.447633\" y=\"49.837553\" style=\"fill: #dd8452; stroke: #333333\"/>\n","     <use xlink:href=\"#m9aca37a79c\" x=\"91.920078\" y=\"69.108955\" style=\"fill: #dd8452; stroke: #333333\"/>\n","     <use xlink:href=\"#m9aca37a79c\" x=\"221.111285\" y=\"184.002335\" style=\"fill: #dd8452; stroke: #333333\"/>\n","     <use xlink:href=\"#m9aca37a79c\" x=\"242.342465\" y=\"191.807442\" style=\"fill: #dd8452; stroke: #333333\"/>\n","     <use xlink:href=\"#m9aca37a79c\" x=\"87.126728\" y=\"69.615823\" style=\"fill: #dd8452; stroke: #333333\"/>\n","     <use xlink:href=\"#m9aca37a79c\" x=\"241.96051\" y=\"187.475249\" style=\"fill: #dd8452; stroke: #333333\"/>\n","     <use xlink:href=\"#m9aca37a79c\" x=\"245.679206\" y=\"196.859347\" style=\"fill: #dd8452; stroke: #333333\"/>\n","     <use xlink:href=\"#m9aca37a79c\" x=\"89.063209\" y=\"58.918704\" style=\"fill: #dd8452; stroke: #333333\"/>\n","     <use xlink:href=\"#m9aca37a79c\" x=\"117.929482\" y=\"58.27104\" style=\"fill: #dd8452; stroke: #333333\"/>\n","     <use xlink:href=\"#m9aca37a79c\" x=\"221.652063\" y=\"192.65811\" style=\"fill: #dd8452; stroke: #333333\"/>\n","     <use xlink:href=\"#m9aca37a79c\" x=\"240.602595\" y=\"199.18325\" style=\"fill: #dd8452; stroke: #333333\"/>\n","     <use xlink:href=\"#m9aca37a79c\" x=\"235.983496\" y=\"198.164219\" style=\"fill: #dd8452; stroke: #333333\"/>\n","     <use xlink:href=\"#m9aca37a79c\" x=\"72.995303\" y=\"59.841842\" style=\"fill: #dd8452; stroke: #333333\"/>\n","     <use xlink:href=\"#m9aca37a79c\" x=\"244.245701\" y=\"210.668637\" style=\"fill: #dd8452; stroke: #333333\"/>\n","     <use xlink:href=\"#m9aca37a79c\" x=\"243.931627\" y=\"184.542294\" style=\"fill: #dd8452; stroke: #333333\"/>\n","     <use xlink:href=\"#m9aca37a79c\" x=\"247.25373\" y=\"184.995806\" style=\"fill: #dd8452; stroke: #333333\"/>\n","     <use xlink:href=\"#m9aca37a79c\" x=\"209.846966\" y=\"194.715263\" style=\"fill: #dd8452; stroke: #333333\"/>\n","     <use xlink:href=\"#m9aca37a79c\" x=\"88.893559\" y=\"71.489405\" style=\"fill: #dd8452; stroke: #333333\"/>\n","     <use xlink:href=\"#m9aca37a79c\" x=\"112.602715\" y=\"37.668135\" style=\"fill: #dd8452; stroke: #333333\"/>\n","     <use xlink:href=\"#m9aca37a79c\" x=\"69.170298\" y=\"66.518021\" style=\"fill: #dd8452; stroke: #333333\"/>\n","     <use xlink:href=\"#m9aca37a79c\" x=\"117.681506\" y=\"60.898123\" style=\"fill: #dd8452; stroke: #333333\"/>\n","     <use xlink:href=\"#m9aca37a79c\" x=\"236.209518\" y=\"196.17688\" style=\"fill: #dd8452; stroke: #333333\"/>\n","     <use xlink:href=\"#m9aca37a79c\" x=\"241.450062\" y=\"148.39173\" style=\"fill: #dd8452; stroke: #333333\"/>\n","     <use xlink:href=\"#m9aca37a79c\" x=\"103.822857\" y=\"52.489559\" style=\"fill: #dd8452; stroke: #333333\"/>\n","     <use xlink:href=\"#m9aca37a79c\" x=\"249.376708\" y=\"192.837243\" style=\"fill: #dd8452; stroke: #333333\"/>\n","     <use xlink:href=\"#m9aca37a79c\" x=\"104.621699\" y=\"69.039111\" style=\"fill: #dd8452; stroke: #333333\"/>\n","     <use xlink:href=\"#m9aca37a79c\" x=\"222.11794\" y=\"197.459392\" style=\"fill: #dd8452; stroke: #333333\"/>\n","     <use xlink:href=\"#m9aca37a79c\" x=\"243.559165\" y=\"192.613408\" style=\"fill: #dd8452; stroke: #333333\"/>\n","     <use xlink:href=\"#m9aca37a79c\" x=\"93.120406\" y=\"64.427992\" style=\"fill: #dd8452; stroke: #333333\"/>\n","     <use xlink:href=\"#m9aca37a79c\" x=\"107.555806\" y=\"63.232008\" style=\"fill: #dd8452; stroke: #333333\"/>\n","     <use xlink:href=\"#m9aca37a79c\" x=\"104.153086\" y=\"76.911117\" style=\"fill: #dd8452; stroke: #333333\"/>\n","     <use xlink:href=\"#m9aca37a79c\" x=\"242.18275\" y=\"190.951763\" style=\"fill: #dd8452; stroke: #333333\"/>\n","     <use xlink:href=\"#m9aca37a79c\" x=\"207.994929\" y=\"162.361706\" style=\"fill: #dd8452; stroke: #333333\"/>\n","     <use xlink:href=\"#m9aca37a79c\" x=\"221.952416\" y=\"171.296789\" style=\"fill: #dd8452; stroke: #333333\"/>\n","     <use xlink:href=\"#m9aca37a79c\" x=\"255.289216\" y=\"194.098057\" style=\"fill: #dd8452; stroke: #333333\"/>\n","     <use xlink:href=\"#m9aca37a79c\" x=\"87.821677\" y=\"66.779562\" style=\"fill: #dd8452; stroke: #333333\"/>\n","     <use xlink:href=\"#m9aca37a79c\" x=\"94.838072\" y=\"71.47917\" style=\"fill: #dd8452; stroke: #333333\"/>\n","     <use xlink:href=\"#m9aca37a79c\" x=\"216.09402\" y=\"193.567972\" style=\"fill: #dd8452; stroke: #333333\"/>\n","     <use xlink:href=\"#m9aca37a79c\" x=\"259.553232\" y=\"188.601648\" style=\"fill: #dd8452; stroke: #333333\"/>\n","     <use xlink:href=\"#m9aca37a79c\" x=\"99.074017\" y=\"71.132649\" style=\"fill: #dd8452; stroke: #333333\"/>\n","     <use xlink:href=\"#m9aca37a79c\" x=\"214.97231\" y=\"169.278805\" style=\"fill: #dd8452; stroke: #333333\"/>\n","     <use xlink:href=\"#m9aca37a79c\" x=\"232.488802\" y=\"195.128251\" style=\"fill: #dd8452; stroke: #333333\"/>\n","     <use xlink:href=\"#m9aca37a79c\" x=\"91.728229\" y=\"70.183479\" style=\"fill: #dd8452; stroke: #333333\"/>\n","     <use xlink:href=\"#m9aca37a79c\" x=\"230.370441\" y=\"221.732228\" style=\"fill: #dd8452; stroke: #333333\"/>\n","     <use xlink:href=\"#m9aca37a79c\" x=\"98.565263\" y=\"46.636599\" style=\"fill: #dd8452; stroke: #333333\"/>\n","     <use xlink:href=\"#m9aca37a79c\" x=\"84.39008\" y=\"62.293726\" style=\"fill: #dd8452; stroke: #333333\"/>\n","     <use xlink:href=\"#m9aca37a79c\" x=\"99.260136\" y=\"76.644525\" style=\"fill: #dd8452; stroke: #333333\"/>\n","     <use xlink:href=\"#m9aca37a79c\" x=\"90.160316\" y=\"48.36918\" style=\"fill: #dd8452; stroke: #333333\"/>\n","     <use xlink:href=\"#m9aca37a79c\" x=\"101.424213\" y=\"51.052371\" style=\"fill: #dd8452; stroke: #333333\"/>\n","     <use xlink:href=\"#m9aca37a79c\" x=\"240.627472\" y=\"215.637913\" style=\"fill: #dd8452; stroke: #333333\"/>\n","     <use xlink:href=\"#m9aca37a79c\" x=\"244.915035\" y=\"196.622401\" style=\"fill: #dd8452; stroke: #333333\"/>\n","     <use xlink:href=\"#m9aca37a79c\" x=\"99.431681\" y=\"51.314124\" style=\"fill: #dd8452; stroke: #333333\"/>\n","     <use xlink:href=\"#m9aca37a79c\" x=\"103.25249\" y=\"65.15402\" style=\"fill: #dd8452; stroke: #333333\"/>\n","     <use xlink:href=\"#m9aca37a79c\" x=\"232.020482\" y=\"198.589794\" style=\"fill: #dd8452; stroke: #333333\"/>\n","     <use xlink:href=\"#m9aca37a79c\" x=\"116.952984\" y=\"70.40264\" style=\"fill: #dd8452; stroke: #333333\"/>\n","     <use xlink:href=\"#m9aca37a79c\" x=\"87.11862\" y=\"61.805133\" style=\"fill: #dd8452; stroke: #333333\"/>\n","     <use xlink:href=\"#m9aca37a79c\" x=\"237.884574\" y=\"187.173383\" style=\"fill: #dd8452; stroke: #333333\"/>\n","     <use xlink:href=\"#m9aca37a79c\" x=\"236.179074\" y=\"198.42297\" style=\"fill: #dd8452; stroke: #333333\"/>\n","     <use xlink:href=\"#m9aca37a79c\" x=\"214.930328\" y=\"192.952472\" style=\"fill: #dd8452; stroke: #333333\"/>\n","     <use xlink:href=\"#m9aca37a79c\" x=\"91.846697\" y=\"70.458646\" style=\"fill: #dd8452; stroke: #333333\"/>\n","     <use xlink:href=\"#m9aca37a79c\" x=\"92.124896\" y=\"50.381341\" style=\"fill: #dd8452; stroke: #333333\"/>\n","     <use xlink:href=\"#m9aca37a79c\" x=\"246.56231\" y=\"191.694573\" style=\"fill: #dd8452; stroke: #333333\"/>\n","     <use xlink:href=\"#m9aca37a79c\" x=\"238.168334\" y=\"212.318606\" style=\"fill: #dd8452; stroke: #333333\"/>\n","     <use xlink:href=\"#m9aca37a79c\" x=\"101.294227\" y=\"49.602815\" style=\"fill: #dd8452; stroke: #333333\"/>\n","     <use xlink:href=\"#m9aca37a79c\" x=\"77.305902\" y=\"65.69555\" style=\"fill: #dd8452; stroke: #333333\"/>\n","     <use xlink:href=\"#m9aca37a79c\" x=\"78.837921\" y=\"35.253133\" style=\"fill: #dd8452; stroke: #333333\"/>\n","     <use xlink:href=\"#m9aca37a79c\" x=\"257.575121\" y=\"206.072093\" style=\"fill: #dd8452; stroke: #333333\"/>\n","     <use xlink:href=\"#m9aca37a79c\" x=\"244.724326\" y=\"173.712313\" style=\"fill: #dd8452; stroke: #333333\"/>\n","     <use xlink:href=\"#m9aca37a79c\" x=\"97.357907\" y=\"72.284562\" style=\"fill: #dd8452; stroke: #333333\"/>\n","     <use xlink:href=\"#m9aca37a79c\" x=\"210.911644\" y=\"189.018121\" style=\"fill: #dd8452; stroke: #333333\"/>\n","     <use xlink:href=\"#m9aca37a79c\" x=\"244.722833\" y=\"182.523587\" style=\"fill: #dd8452; stroke: #333333\"/>\n","     <use xlink:href=\"#m9aca37a79c\" x=\"123.086743\" y=\"53.240219\" style=\"fill: #dd8452; stroke: #333333\"/>\n","     <use xlink:href=\"#m9aca37a79c\" x=\"106.171614\" y=\"59.252583\" style=\"fill: #dd8452; stroke: #333333\"/>\n","     <use xlink:href=\"#m9aca37a79c\" x=\"240.625168\" y=\"203.899291\" style=\"fill: #dd8452; stroke: #333333\"/>\n","     <use xlink:href=\"#m9aca37a79c\" x=\"227.090912\" y=\"185.119846\" style=\"fill: #dd8452; stroke: #333333\"/>\n","     <use xlink:href=\"#m9aca37a79c\" x=\"230.631352\" y=\"182.486538\" style=\"fill: #dd8452; stroke: #333333\"/>\n","     <use xlink:href=\"#m9aca37a79c\" x=\"97.601934\" y=\"60.013628\" style=\"fill: #dd8452; stroke: #333333\"/>\n","     <use xlink:href=\"#m9aca37a79c\" x=\"76.664759\" y=\"56.482177\" style=\"fill: #dd8452; stroke: #333333\"/>\n","     <use xlink:href=\"#m9aca37a79c\" x=\"226.222567\" y=\"194.984609\" style=\"fill: #dd8452; stroke: #333333\"/>\n","     <use xlink:href=\"#m9aca37a79c\" x=\"101.886409\" y=\"74.273287\" style=\"fill: #dd8452; stroke: #333333\"/>\n","     <use xlink:href=\"#m9aca37a79c\" x=\"224.081317\" y=\"199.290469\" style=\"fill: #dd8452; stroke: #333333\"/>\n","     <use xlink:href=\"#m9aca37a79c\" x=\"82.850158\" y=\"87.330048\" style=\"fill: #dd8452; stroke: #333333\"/>\n","     <use xlink:href=\"#m9aca37a79c\" x=\"256.455382\" y=\"180.013474\" style=\"fill: #dd8452; stroke: #333333\"/>\n","     <use xlink:href=\"#m9aca37a79c\" x=\"252.117577\" y=\"197.280893\" style=\"fill: #dd8452; stroke: #333333\"/>\n","     <use xlink:href=\"#m9aca37a79c\" x=\"84.941787\" y=\"35.742009\" style=\"fill: #dd8452; stroke: #333333\"/>\n","     <use xlink:href=\"#m9aca37a79c\" x=\"74.890082\" y=\"32.725883\" style=\"fill: #dd8452; stroke: #333333\"/>\n","     <use xlink:href=\"#m9aca37a79c\" x=\"78.286377\" y=\"58.799707\" style=\"fill: #dd8452; stroke: #333333\"/>\n","     <use xlink:href=\"#m9aca37a79c\" x=\"94.369095\" y=\"51.678149\" style=\"fill: #dd8452; stroke: #333333\"/>\n","     <use xlink:href=\"#m9aca37a79c\" x=\"93.538963\" y=\"60.376048\" style=\"fill: #dd8452; stroke: #333333\"/>\n","     <use xlink:href=\"#m9aca37a79c\" x=\"103.156822\" y=\"54.7037\" style=\"fill: #dd8452; stroke: #333333\"/>\n","     <use xlink:href=\"#m9aca37a79c\" x=\"240.145732\" y=\"179.753269\" style=\"fill: #dd8452; stroke: #333333\"/>\n","    </g>\n","   </g>\n","   <g id=\"patch_3\">\n","    <path d=\"M 59.024844 244.078125 \n","L 59.024844 22.318125 \n","\" style=\"fill: none; stroke: #ffffff; stroke-width: 1.25; stroke-linejoin: miter; stroke-linecap: square\"/>\n","   </g>\n","   <g id=\"patch_4\">\n","    <path d=\"M 282.224844 244.078125 \n","L 282.224844 22.318125 \n","\" style=\"fill: none; stroke: #ffffff; stroke-width: 1.25; stroke-linejoin: miter; stroke-linecap: square\"/>\n","   </g>\n","   <g id=\"patch_5\">\n","    <path d=\"M 59.024844 244.078125 \n","L 282.224844 244.078125 \n","\" style=\"fill: none; stroke: #ffffff; stroke-width: 1.25; stroke-linejoin: miter; stroke-linecap: square\"/>\n","   </g>\n","   <g id=\"patch_6\">\n","    <path d=\"M 59.024844 22.318125 \n","L 282.224844 22.318125 \n","\" style=\"fill: none; stroke: #ffffff; stroke-width: 1.25; stroke-linejoin: miter; stroke-linecap: square\"/>\n","   </g>\n","   <g id=\"text_14\">\n","    <!-- Dataset samples -->\n","    <g style=\"fill: #262626\" transform=\"translate(120.282031 16.318125) scale(0.12 -0.12)\">\n","     <defs>\n","      <path id=\"DejaVuSans-44\" d=\"M 1259 4147 \n","L 1259 519 \n","L 2022 519 \n","Q 2988 519 3436 956 \n","Q 3884 1394 3884 2338 \n","Q 3884 3275 3436 3711 \n","Q 2988 4147 2022 4147 \n","L 1259 4147 \n","z\n","M 628 4666 \n","L 1925 4666 \n","Q 3281 4666 3915 4102 \n","Q 4550 3538 4550 2338 \n","Q 4550 1131 3912 565 \n","Q 3275 0 1925 0 \n","L 628 0 \n","L 628 4666 \n","z\n","\" transform=\"scale(0.015625)\"/>\n","      <path id=\"DejaVuSans-61\" d=\"M 2194 1759 \n","Q 1497 1759 1228 1600 \n","Q 959 1441 959 1056 \n","Q 959 750 1161 570 \n","Q 1363 391 1709 391 \n","Q 2188 391 2477 730 \n","Q 2766 1069 2766 1631 \n","L 2766 1759 \n","L 2194 1759 \n","z\n","M 3341 1997 \n","L 3341 0 \n","L 2766 0 \n","L 2766 531 \n","Q 2569 213 2275 61 \n","Q 1981 -91 1556 -91 \n","Q 1019 -91 701 211 \n","Q 384 513 384 1019 \n","Q 384 1609 779 1909 \n","Q 1175 2209 1959 2209 \n","L 2766 2209 \n","L 2766 2266 \n","Q 2766 2663 2505 2880 \n","Q 2244 3097 1772 3097 \n","Q 1472 3097 1187 3025 \n","Q 903 2953 641 2809 \n","L 641 3341 \n","Q 956 3463 1253 3523 \n","Q 1550 3584 1831 3584 \n","Q 2591 3584 2966 3190 \n","Q 3341 2797 3341 1997 \n","z\n","\" transform=\"scale(0.015625)\"/>\n","      <path id=\"DejaVuSans-74\" d=\"M 1172 4494 \n","L 1172 3500 \n","L 2356 3500 \n","L 2356 3053 \n","L 1172 3053 \n","L 1172 1153 \n","Q 1172 725 1289 603 \n","Q 1406 481 1766 481 \n","L 2356 481 \n","L 2356 0 \n","L 1766 0 \n","Q 1100 0 847 248 \n","Q 594 497 594 1153 \n","L 594 3053 \n","L 172 3053 \n","L 172 3500 \n","L 594 3500 \n","L 594 4494 \n","L 1172 4494 \n","z\n","\" transform=\"scale(0.015625)\"/>\n","      <path id=\"DejaVuSans-73\" d=\"M 2834 3397 \n","L 2834 2853 \n","Q 2591 2978 2328 3040 \n","Q 2066 3103 1784 3103 \n","Q 1356 3103 1142 2972 \n","Q 928 2841 928 2578 \n","Q 928 2378 1081 2264 \n","Q 1234 2150 1697 2047 \n","L 1894 2003 \n","Q 2506 1872 2764 1633 \n","Q 3022 1394 3022 966 \n","Q 3022 478 2636 193 \n","Q 2250 -91 1575 -91 \n","Q 1294 -91 989 -36 \n","Q 684 19 347 128 \n","L 347 722 \n","Q 666 556 975 473 \n","Q 1284 391 1588 391 \n","Q 1994 391 2212 530 \n","Q 2431 669 2431 922 \n","Q 2431 1156 2273 1281 \n","Q 2116 1406 1581 1522 \n","L 1381 1569 \n","Q 847 1681 609 1914 \n","Q 372 2147 372 2553 \n","Q 372 3047 722 3315 \n","Q 1072 3584 1716 3584 \n","Q 2034 3584 2315 3537 \n","Q 2597 3491 2834 3397 \n","z\n","\" transform=\"scale(0.015625)\"/>\n","      <path id=\"DejaVuSans-65\" d=\"M 3597 1894 \n","L 3597 1613 \n","L 953 1613 \n","Q 991 1019 1311 708 \n","Q 1631 397 2203 397 \n","Q 2534 397 2845 478 \n","Q 3156 559 3463 722 \n","L 3463 178 \n","Q 3153 47 2828 -22 \n","Q 2503 -91 2169 -91 \n","Q 1331 -91 842 396 \n","Q 353 884 353 1716 \n","Q 353 2575 817 3079 \n","Q 1281 3584 2069 3584 \n","Q 2775 3584 3186 3129 \n","Q 3597 2675 3597 1894 \n","z\n","M 3022 2063 \n","Q 3016 2534 2758 2815 \n","Q 2500 3097 2075 3097 \n","Q 1594 3097 1305 2825 \n","Q 1016 2553 972 2059 \n","L 3022 2063 \n","z\n","\" transform=\"scale(0.015625)\"/>\n","      <path id=\"DejaVuSans-20\" transform=\"scale(0.015625)\"/>\n","      <path id=\"DejaVuSans-6d\" d=\"M 3328 2828 \n","Q 3544 3216 3844 3400 \n","Q 4144 3584 4550 3584 \n","Q 5097 3584 5394 3201 \n","Q 5691 2819 5691 2113 \n","L 5691 0 \n","L 5113 0 \n","L 5113 2094 \n","Q 5113 2597 4934 2840 \n","Q 4756 3084 4391 3084 \n","Q 3944 3084 3684 2787 \n","Q 3425 2491 3425 1978 \n","L 3425 0 \n","L 2847 0 \n","L 2847 2094 \n","Q 2847 2600 2669 2842 \n","Q 2491 3084 2119 3084 \n","Q 1678 3084 1418 2786 \n","Q 1159 2488 1159 1978 \n","L 1159 0 \n","L 581 0 \n","L 581 3500 \n","L 1159 3500 \n","L 1159 2956 \n","Q 1356 3278 1631 3431 \n","Q 1906 3584 2284 3584 \n","Q 2666 3584 2933 3390 \n","Q 3200 3197 3328 2828 \n","z\n","\" transform=\"scale(0.015625)\"/>\n","      <path id=\"DejaVuSans-70\" d=\"M 1159 525 \n","L 1159 -1331 \n","L 581 -1331 \n","L 581 3500 \n","L 1159 3500 \n","L 1159 2969 \n","Q 1341 3281 1617 3432 \n","Q 1894 3584 2278 3584 \n","Q 2916 3584 3314 3078 \n","Q 3713 2572 3713 1747 \n","Q 3713 922 3314 415 \n","Q 2916 -91 2278 -91 \n","Q 1894 -91 1617 61 \n","Q 1341 213 1159 525 \n","z\n","M 3116 1747 \n","Q 3116 2381 2855 2742 \n","Q 2594 3103 2138 3103 \n","Q 1681 3103 1420 2742 \n","Q 1159 2381 1159 1747 \n","Q 1159 1113 1420 752 \n","Q 1681 391 2138 391 \n","Q 2594 391 2855 752 \n","Q 3116 1113 3116 1747 \n","z\n","\" transform=\"scale(0.015625)\"/>\n","      <path id=\"DejaVuSans-6c\" d=\"M 603 4863 \n","L 1178 4863 \n","L 1178 0 \n","L 603 0 \n","L 603 4863 \n","z\n","\" transform=\"scale(0.015625)\"/>\n","     </defs>\n","     <use xlink:href=\"#DejaVuSans-44\"/>\n","     <use xlink:href=\"#DejaVuSans-61\" x=\"77.001953\"/>\n","     <use xlink:href=\"#DejaVuSans-74\" x=\"138.28125\"/>\n","     <use xlink:href=\"#DejaVuSans-61\" x=\"177.490234\"/>\n","     <use xlink:href=\"#DejaVuSans-73\" x=\"238.769531\"/>\n","     <use xlink:href=\"#DejaVuSans-65\" x=\"290.869141\"/>\n","     <use xlink:href=\"#DejaVuSans-74\" x=\"352.392578\"/>\n","     <use xlink:href=\"#DejaVuSans-20\" x=\"391.601562\"/>\n","     <use xlink:href=\"#DejaVuSans-73\" x=\"423.388672\"/>\n","     <use xlink:href=\"#DejaVuSans-61\" x=\"475.488281\"/>\n","     <use xlink:href=\"#DejaVuSans-6d\" x=\"536.767578\"/>\n","     <use xlink:href=\"#DejaVuSans-70\" x=\"634.179688\"/>\n","     <use xlink:href=\"#DejaVuSans-6c\" x=\"697.65625\"/>\n","     <use xlink:href=\"#DejaVuSans-65\" x=\"725.439453\"/>\n","     <use xlink:href=\"#DejaVuSans-73\" x=\"786.962891\"/>\n","    </g>\n","   </g>\n","   <g id=\"legend_1\">\n","    <g id=\"patch_7\">\n","     <path d=\"M 66.724844 150.994063 \n","L 141.358125 150.994063 \n","Q 143.558125 150.994063 143.558125 148.794063 \n","L 143.558125 117.602188 \n","Q 143.558125 115.402188 141.358125 115.402188 \n","L 66.724844 115.402188 \n","Q 64.524844 115.402188 64.524844 117.602188 \n","L 64.524844 148.794063 \n","Q 64.524844 150.994063 66.724844 150.994063 \n","z\n","\" style=\"fill: #eaeaf2; opacity: 0.8; stroke: #cccccc; stroke-linejoin: miter\"/>\n","    </g>\n","    <g id=\"PathCollection_3\">\n","     <g>\n","      <use xlink:href=\"#mb6a8ea5cf4\" x=\"79.924844\" y=\"125.272969\" style=\"fill: #4c72b0; stroke: #333333\"/>\n","     </g>\n","    </g>\n","    <g id=\"text_15\">\n","     <!-- Class 0 -->\n","     <g style=\"fill: #262626\" transform=\"translate(99.724844 128.160469) scale(0.11 -0.11)\">\n","      <defs>\n","       <path id=\"DejaVuSans-43\" d=\"M 4122 4306 \n","L 4122 3641 \n","Q 3803 3938 3442 4084 \n","Q 3081 4231 2675 4231 \n","Q 1875 4231 1450 3742 \n","Q 1025 3253 1025 2328 \n","Q 1025 1406 1450 917 \n","Q 1875 428 2675 428 \n","Q 3081 428 3442 575 \n","Q 3803 722 4122 1019 \n","L 4122 359 \n","Q 3791 134 3420 21 \n","Q 3050 -91 2638 -91 \n","Q 1578 -91 968 557 \n","Q 359 1206 359 2328 \n","Q 359 3453 968 4101 \n","Q 1578 4750 2638 4750 \n","Q 3056 4750 3426 4639 \n","Q 3797 4528 4122 4306 \n","z\n","\" transform=\"scale(0.015625)\"/>\n","      </defs>\n","      <use xlink:href=\"#DejaVuSans-43\"/>\n","      <use xlink:href=\"#DejaVuSans-6c\" x=\"69.824219\"/>\n","      <use xlink:href=\"#DejaVuSans-61\" x=\"97.607422\"/>\n","      <use xlink:href=\"#DejaVuSans-73\" x=\"158.886719\"/>\n","      <use xlink:href=\"#DejaVuSans-73\" x=\"210.986328\"/>\n","      <use xlink:href=\"#DejaVuSans-20\" x=\"263.085938\"/>\n","      <use xlink:href=\"#DejaVuSans-30\" x=\"294.873047\"/>\n","     </g>\n","    </g>\n","    <g id=\"PathCollection_4\">\n","     <g>\n","      <use xlink:href=\"#m9aca37a79c\" x=\"79.924844\" y=\"141.418906\" style=\"fill: #dd8452; stroke: #333333\"/>\n","     </g>\n","    </g>\n","    <g id=\"text_16\">\n","     <!-- Class 1 -->\n","     <g style=\"fill: #262626\" transform=\"translate(99.724844 144.306406) scale(0.11 -0.11)\">\n","      <use xlink:href=\"#DejaVuSans-43\"/>\n","      <use xlink:href=\"#DejaVuSans-6c\" x=\"69.824219\"/>\n","      <use xlink:href=\"#DejaVuSans-61\" x=\"97.607422\"/>\n","      <use xlink:href=\"#DejaVuSans-73\" x=\"158.886719\"/>\n","      <use xlink:href=\"#DejaVuSans-73\" x=\"210.986328\"/>\n","      <use xlink:href=\"#DejaVuSans-20\" x=\"263.085938\"/>\n","      <use xlink:href=\"#DejaVuSans-31\" x=\"294.873047\"/>\n","     </g>\n","    </g>\n","   </g>\n","  </g>\n"," </g>\n"," <defs>\n","  <clipPath id=\"pa3c92064d6\">\n","   <rect x=\"59.024844\" y=\"22.318125\" width=\"223.2\" height=\"221.76\"/>\n","  </clipPath>\n"," </defs>\n","</svg>\n"],"text/plain":["<Figure size 400x400 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["visualize_samples(dataset.data, dataset.label)\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"DaVX9GEqiqm1"},"source":["#### The data loader class\n","\n","The class `torch.utils.data.DataLoader` represents a Python iterable over a dataset with support for automatic batching, multi-process data loading and many more features. The data loader communicates with the dataset using the function `__getitem__`, and stacks its outputs as tensors over the first dimension to form a batch.\n","In contrast to the dataset class, we usually don't have to define our own data loader class, but can just create an object of it with the dataset as input. Additionally, we can configure our data loader with the following input arguments (only a selection, see full list [here](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader)):\n","\n","* `batch_size`: Number of samples to stack per batch\n","* `shuffle`: If True, the data is returned in a random order. This is important during training for introducing stochasticity. \n","* `num_workers`: Number of subprocesses to use for data loading. The default, 0, means that the data will be loaded in the main process which can slow down training for datasets where loading a data point takes a considerable amount of time (e.g. large images). More workers are recommended for those, but can cause issues on Windows computers. For tiny datasets as ours, 0 workers are usually faster.\n","* `pin_memory`: If True, the data loader will copy Tensors into CUDA pinned memory before returning them. This can save some time for large data points on GPUs. Usually a good practice to use for a training set, but not necessarily for validation and test to save memory on the GPU.\n","* `drop_last`: If True, the last batch is dropped in case it is smaller than the specified batch size. This occurs when the dataset size is not a multiple of the batch size. Only potentially helpful during training to keep a consistent batch size.\n","\n","Let's create a simple data loader below:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":938,"status":"ok","timestamp":1681658788993,"user":{"displayName":"Dr CAO Yixin _","userId":"02213333189428679281"},"user_tz":-480},"id":"Bls9PVIXiqcd","outputId":"53ce05f7-52d7-42ea-b1d9-6a00495d658d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Data inputs torch.Size([8, 2]) \n"," tensor([[-0.1317,  0.0158],\n","        [-0.1791,  1.0093],\n","        [ 1.1914,  0.0338],\n","        [ 0.0273,  0.2731],\n","        [-0.0415,  0.9310],\n","        [ 1.0368,  1.0705],\n","        [-0.1474,  0.9650],\n","        [ 1.0522, -0.0464]])\n","Data labels torch.Size([8]) \n"," tensor([0, 1, 1, 0, 1, 0, 1, 1])\n"]}],"source":["data_loader = data.DataLoader(dataset, batch_size=8, shuffle=True)\n","# next(iter(...)) catches the first batch of the data loader\n","# If shuffle is True, this will return a different batch every time we run this cell\n","# For iterating over the whole dataset, we can simple use \"for batch in data_loader: ...\"\n","data_inputs, data_labels = next(iter(data_loader))\n","\n","# The shape of the outputs are [batch_size, d_1,...,d_N] where d_1,...,d_N are the \n","# dimensions of the data point returned from the dataset class\n","print(\"Data inputs\", data_inputs.shape, \"\\n\", data_inputs)\n","print(\"Data labels\", data_labels.shape, \"\\n\", data_labels)"]},{"cell_type":"markdown","metadata":{"id":"ORKG-xxs2br1"},"source":["### Optimization\n","\n","After defining the model and the dataset, it is time to prepare the optimization of the model. During training, we will perform the following steps:\n","\n","1. Get a batch from the data loader\n","2. Obtain the predictions from the model for the batch\n","3. Calculate the loss based on the difference between predictions and labels\n","4. Backpropagation: calculate the gradients for every parameter with respect to the loss\n","5. Update the parameters of the model in the direction of the gradients\n","\n","We have seen how we can do step 1, 2 and 4 in PyTorch. Now, we will look at step 3 and 5."]},{"cell_type":"markdown","metadata":{"id":"i38rtgeyi3xg"},"source":["#### Loss modules\n","\n","We can calculate the loss for a batch by simply performing a few tensor operations as those are automatically added to the computation graph. For instance, for binary classification, we can use Binary Cross Entropy (BCE) which is defined as follows:\n","\n","$$\\mathcal{L}_{BCE} = -\\sum_i \\left[ y_i \\log x_i + (1 - y_i) \\log (1 - x_i) \\right]$$\n","\n","where $y$ are our labels, and $x$ our predictions, both in the range of $[0,1]$. However, PyTorch already provides a list of predefined loss functions which we can use (see [here](https://pytorch.org/docs/stable/nn.html#loss-functions) for a full list). For instance, for BCE, PyTorch has two modules: `nn.BCELoss()`, `nn.BCEWithLogitsLoss()`. While `nn.BCELoss` expects the inputs $x$ to be in the range $[0,1]$, i.e. the output of a sigmoid, `nn.BCEWithLogitsLoss` combines a sigmoid layer and the BCE loss in a single class. This version is numerically more stable than using a plain Sigmoid followed by a BCE loss because of the logarithms applied in the loss function. Hence, it is adviced to use loss functions applied on \"logits\" where possible (remember to not apply a sigmoid on the output of the model in this case!). For our model defined above, we therefore use the module `nn.BCEWithLogitsLoss`. "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tjnSMotsi26w"},"outputs":[],"source":["loss_module = nn.BCEWithLogitsLoss()"]},{"cell_type":"markdown","metadata":{"id":"gYixEUPsjCTP"},"source":["#### Stochastic Gradient Descent\n","\n","For updating the parameters, PyTorch provides the package `torch.optim` that has most popular optimizers implemented. We will discuss the specific optimizers and their differences later in the course, but will for now use the simplest of them: `torch.optim.SGD`. Stochastic Gradient Descent updates parameters by multiplying the gradients with a small constant, called learning rate, and subtracting those from the parameters (hence minimizing the loss). Therefore, we slowly move towards the direction of minimizing the loss. A good default value of the learning rate for a small network as ours is 0.1. "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EEwNVYqk2gq8"},"outputs":[],"source":["# Input to the optimizer are the parameters of the model: model.parameters()\n","optimizer = torch.optim.SGD(model.parameters(), lr=0.1)"]},{"cell_type":"markdown","metadata":{"id":"TML9k2gAjLbr"},"source":["The optimizer provides two useful functions: `optimizer.step()`, and `optimizer.zero_grad()`. The step function updates the parameters based on the gradients as explained above. The function `optimizer.zero_grad()` sets the gradients of all parameters to zero. While this function seems less relevant at first, it is a crucial pre-step before performing backpropagation. If we call the `backward` function on the loss while the parameter gradients are non-zero from the previous batch, the new gradients would actually be added to the previous ones instead of overwriting them. This is done because a parameter might occur multiple times in a computation graph, and we need to sum the gradients in this case instead of replacing them. Hence, remember to call `optimizer.zero_grad()` before calculating the gradients of a batch."]},{"cell_type":"markdown","metadata":{"id":"tKKG5I4djT_V"},"source":["### Training\n","\n","Finally, we are ready to train our model. As a first step, we create a slightly larger dataset and specify a data loader with a larger batch size. "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9RTyu7bi2nO1"},"outputs":[],"source":["train_dataset = XORDataset(size=2500)\n","train_data_loader = data.DataLoader(train_dataset, batch_size=128, shuffle=True)"]},{"cell_type":"markdown","metadata":{"id":"KxyoXnzujaVt"},"source":["Now, we can write a small training function. Remember our five steps: load a batch, obtain the predictions, calculate the loss, backpropagate, and update. Additionally, we have to push all data and model parameters to the device of our choice (GPU if available). For the tiny neural network we have, communicating the data to the GPU actually takes much more time than we could save from running the operation on GPU. For large networks, the communication time is significantly smaller than the actual runtime making a GPU crucial in these cases.\n","\n","Here we introduce how to detect and set your device. "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5342,"status":"ok","timestamp":1681658808606,"user":{"displayName":"Dr CAO Yixin _","userId":"02213333189428679281"},"user_tz":-480},"id":"UQ3aViQC22lf","outputId":"6713b1ef-05ea-4855-ffdb-1bf80a7f6371"},"outputs":[{"name":"stdout","output_type":"stream","text":["Is the GPU available? True\n","Device cuda\n"]},{"data":{"text/plain":["SimpleClassifier(\n","  (linear1): Linear(in_features=2, out_features=4, bias=True)\n","  (act_fn): Tanh()\n","  (linear2): Linear(in_features=4, out_features=1, bias=True)\n",")"]},"execution_count":48,"metadata":{},"output_type":"execute_result"}],"source":["gpu_avail = torch.cuda.is_available()\n","print(f\"Is the GPU available? {gpu_avail}\")\n","\n","device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n","print(\"Device\", device)\n","\n","# GPU operations have a separate seed we also want to set\n","if torch.cuda.is_available(): \n","    torch.cuda.manual_seed(42)\n","    torch.cuda.manual_seed_all(42)\n","    \n","# Additionally, some operations on a GPU are implemented stochastic for efficiency\n","# We want to ensure that all operations are deterministic on GPU (if used) for reproducibility\n","torch.backends.cudnn.deterministic = True\n","torch.backends.cudnn.benchmark = False\n","\n","# Push model to device. Has to be only done once\n","model.to(device)"]},{"cell_type":"markdown","metadata":{"id":"zTJ772q8kLiu"},"source":["In addition, we set our model to training mode. This is done by calling `model.train()`. There exist certain modules that need to perform a different forward step during training than during testing (e.g. BatchNorm and Dropout), and we can switch between them using `model.train()` and `model.eval()`."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bOKQyaET25Fl"},"outputs":[],"source":["## Progress bar\n","from tqdm.notebook import tqdm\n","\n","def train_model(model, optimizer, data_loader, loss_module, num_epochs=100):\n","    # Set model to train mode\n","    model.train() \n","    \n","    # Training loop\n","    for epoch in tqdm(range(num_epochs)):\n","        for data_inputs, data_labels in data_loader:\n","            \n","            ## Step 1: Move input data to device (only strictly necessary if we use GPU)\n","            data_inputs = data_inputs.to(device)\n","            data_labels = data_labels.to(device)\n","            \n","            ## Step 2: Run the model on the input data\n","            #######################################################\n","            #### 完善代码3： 根据model和data_inputs得出预测值preds\n","            #### preds = \n","            #######################################################\n","            \n","            ## Step 3: Calculate the loss\n","            ##############################################\n","            #### 完善代码4：根据预测值和标签实际值，计算loss\n","            #### loss = \n","            ##############################################\n","            \n","            ## Step 4: Perform backpropagation\n","            # Before calculating the gradients, we need to ensure that they are all zero. \n","            # The gradients would not be overwritten, but actually added to the existing ones.\n","            optimizer.zero_grad() \n","            # Perform backpropagation\n","            loss.backward()\n","            \n","            ## Step 5: Update the parameters\n","            optimizer.step()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["617d213e43ad4d9e85b5ccc3eb19d83a","0b769b19e72341d9b17191789c949b39","4830a6a1c05c4e4eabe66253e0f102f5","baef1b2b28ee460fbcdf5cdf389edd2f","955e7a6650a541ebae2cb39918b588be","d631119f4021432d913a6a2559c1122e","7decdfa9861c49d5b344a96069901087","7e779137fc4645918346a9c5dd9ce554","38cb6f036cdb4ffb8a845089ec484dec","bee2db720c6d48a2b2d4dd90681252e7","a2e54e29b0b045d68e4264d9d6be471b"]},"executionInfo":{"elapsed":7762,"status":"ok","timestamp":1681658828143,"user":{"displayName":"Dr CAO Yixin _","userId":"02213333189428679281"},"user_tz":-480},"id":"E2OI60l5kQ7h","outputId":"53b76f1a-f4af-4a37-c939-5324db1c9631"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"617d213e43ad4d9e85b5ccc3eb19d83a","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/100 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"}],"source":["train_model(model, optimizer, train_data_loader, loss_module)"]},{"cell_type":"markdown","metadata":{"id":"wY_2AxtakdGi"},"source":["#### Saving a model\n","\n","After finish training a model, we save the model to disk so that we can load the same weights at a later time. For this, we extract the so-called `state_dict` from the model which contains all learnable parameters. For our simple model, the state dict contains the following entries:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":287,"status":"ok","timestamp":1681658843128,"user":{"displayName":"Dr CAO Yixin _","userId":"02213333189428679281"},"user_tz":-480},"id":"JMV5ESlFkfKS","outputId":"75a1667a-a7bc-4a4b-8294-1b9ddb2ace24"},"outputs":[{"name":"stdout","output_type":"stream","text":["OrderedDict([('linear1.weight', tensor([[-2.6063,  3.4253],\n","        [-3.2947,  2.3557],\n","        [-0.0257, -0.3351],\n","        [ 2.1080,  2.1714]], device='cuda:0')), ('linear1.bias', tensor([ 1.0122, -0.8667,  0.1184, -0.3365], device='cuda:0')), ('linear2.weight', tensor([[-4.4144,  4.4110,  0.3198,  3.2606]], device='cuda:0')), ('linear2.bias', tensor([1.4145], device='cuda:0'))])\n"]}],"source":["state_dict = model.state_dict()\n","print(state_dict)"]},{"cell_type":"markdown","metadata":{"id":"wlUQQeVU8weO"},"source":["To save the state dictionary, we can use `torch.save`:\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZhvuiZlM85n2"},"outputs":[],"source":["# torch.save(object, filename). For the filename, any extension can be used\n","torch.save(state_dict, \"our_model.tar\")"]},{"cell_type":"markdown","metadata":{"id":"CXVTuYVgky3H"},"source":["To load a model from a state dict, we use the function `torch.load` to load the state dict from the disk, and the module function `load_state_dict` to overwrite our parameters with the new values:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":268,"status":"ok","timestamp":1681658852433,"user":{"displayName":"Dr CAO Yixin _","userId":"02213333189428679281"},"user_tz":-480},"id":"EuzOxYyo89Q1","outputId":"da6be275-f525-433b-8b8d-454c3e62726c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Original model\n"," OrderedDict([('linear1.weight', tensor([[-2.6063,  3.4253],\n","        [-3.2947,  2.3557],\n","        [-0.0257, -0.3351],\n","        [ 2.1080,  2.1714]], device='cuda:0')), ('linear1.bias', tensor([ 1.0122, -0.8667,  0.1184, -0.3365], device='cuda:0')), ('linear2.weight', tensor([[-4.4144,  4.4110,  0.3198,  3.2606]], device='cuda:0')), ('linear2.bias', tensor([1.4145], device='cuda:0'))])\n","\n","Loaded model\n"," OrderedDict([('linear1.weight', tensor([[-2.6063,  3.4253],\n","        [-3.2947,  2.3557],\n","        [-0.0257, -0.3351],\n","        [ 2.1080,  2.1714]])), ('linear1.bias', tensor([ 1.0122, -0.8667,  0.1184, -0.3365])), ('linear2.weight', tensor([[-4.4144,  4.4110,  0.3198,  3.2606]])), ('linear2.bias', tensor([1.4145]))])\n"]}],"source":["# Load state dict from the disk (make sure it is the same name as above)\n","state_dict = torch.load(\"our_model.tar\")\n","\n","# Create a new model and load the state\n","new_model = SimpleClassifier(num_inputs=2, num_hidden=4, num_outputs=1)\n","new_model.load_state_dict(state_dict)\n","\n","# Verify that the parameters are the same\n","print(\"Original model\\n\", model.state_dict())\n","print(\"\\nLoaded model\\n\", new_model.state_dict())"]},{"cell_type":"markdown","metadata":{"id":"zQ241Ay-k4O3"},"source":["A detailed tutorial on saving and loading models in PyTorch can be found [here](https://pytorch.org/tutorials/beginner/saving_loading_models.html)."]},{"cell_type":"markdown","metadata":{"id":"G_uTmxoz3MSF"},"source":["### Evaluation\n","\n","Once we have trained a model, it is time to evaluate it on a held-out test set. As our dataset consist of randomly generated data points, we need to first create a test set with a corresponding data loader."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zrsUH6Yw3PUl"},"outputs":[],"source":["test_dataset = XORDataset(size=500)\n","# drop_last -> Don't drop the last batch although it is smaller than 128\n","test_data_loader = data.DataLoader(test_dataset, batch_size=128, shuffle=False, drop_last=False) "]},{"cell_type":"markdown","metadata":{"id":"NkSplsc8yeUl"},"source":["As metric, we will use accuracy which is calculated as follows:\n","\n","$$acc = \\frac{\\#\\text{correct predictions}}{\\#\\text{all predictions}} = \\frac{TP+TN}{TP+TN+FP+FN}$$\n","\n","where TP are the true positives, TN true negatives, FP false positives, and FN the fale negatives. \n","\n","When evaluating the model, we don't need to keep track of the computation graph as we don't intend to calculate the gradients. This reduces the required memory and speed up the model. In PyTorch, we can deactivate the computation graph using `with torch.no_grad(): ...`. Remember to additionally set the model to eval mode."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ds1l3JKC67D2"},"outputs":[],"source":["def eval_model(model, data_loader):\n","    model.eval() # Set model to eval mode\n","    true_preds, num_preds = 0., 0.\n","    \n","    with torch.no_grad(): # Deactivate gradients for the following code\n","        for data_inputs, data_labels in data_loader:\n","            \n","            # Determine prediction of model on dev set\n","            ############################################################\n","            #### 完善代码5：将data_inputs，data_labels加载到指定device上\n","            #### data_inputs, data_labels = \n","            ############################################################\n","            preds = model(data_inputs)\n","            preds = torch.sigmoid(preds) # Sigmoid to map predictions between 0 and 1\n","            pred_labels = (preds >= 0.5).long() # Binarize predictions to 0 and 1\n","            \n","            # Keep records of predictions for the accuracy metric (true_preds=TP+TN, num_preds=TP+TN+FP+FN)\n","            true_preds += (pred_labels == data_labels).sum()\n","            num_preds += data_labels.shape[0]\n","            \n","    acc = true_preds / num_preds\n","    print(f\"Accuracy of the model: {100.0*acc:4.2f}%\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":491,"status":"ok","timestamp":1681658872510,"user":{"displayName":"Dr CAO Yixin _","userId":"02213333189428679281"},"user_tz":-480},"id":"s6WCZu5elM5E","outputId":"4451da99-e226-49f2-ad66-5fabafd9d5ab"},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy of the model: 100.00%\n"]}],"source":["eval_model(model, test_data_loader)"]},{"cell_type":"markdown","metadata":{"id":"S-IGgpd-lfNe"},"source":["If we trained our model correctly, we should see a score close to 100% accuracy. However, this is only possible because of our simple task, and unfortunately, we usually don't get such high scores on test sets of more complex tasks."]},{"cell_type":"markdown","metadata":{"id":"79NshWDX6_f1"},"source":["## Additional features we didn't get to discuss yet\n","\n","Finally, you are all set to start with your own PyTorch project! In summary, we have looked at how we can build neural networks in PyTorch, and train and test them on data. However, there is still much more to PyTorch we haven't discussed yet. In the coming series of Jupyter notebooks, we will discover more and more functionalities of PyTorch, so that you also get familiar to PyTorch concepts beyond the basics. If you are already interested in learning more of PyTorch, we recommend the official [tutorial website](https://pytorch.org/tutorials/) that contains many tutorials on various topics. Especially logging with Tensorboard ([official tutorial here](https://pytorch.org/tutorials/intermediate/tensorboard_tutorial.html)) is a good practice."]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"widgets":{"application/vnd.jupyter.widget-state+json":{"0b769b19e72341d9b17191789c949b39":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d631119f4021432d913a6a2559c1122e","placeholder":"​","style":"IPY_MODEL_7decdfa9861c49d5b344a96069901087","value":"100%"}},"38cb6f036cdb4ffb8a845089ec484dec":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4830a6a1c05c4e4eabe66253e0f102f5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7e779137fc4645918346a9c5dd9ce554","max":100,"min":0,"orientation":"horizontal","style":"IPY_MODEL_38cb6f036cdb4ffb8a845089ec484dec","value":100}},"617d213e43ad4d9e85b5ccc3eb19d83a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0b769b19e72341d9b17191789c949b39","IPY_MODEL_4830a6a1c05c4e4eabe66253e0f102f5","IPY_MODEL_baef1b2b28ee460fbcdf5cdf389edd2f"],"layout":"IPY_MODEL_955e7a6650a541ebae2cb39918b588be"}},"7decdfa9861c49d5b344a96069901087":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7e779137fc4645918346a9c5dd9ce554":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"955e7a6650a541ebae2cb39918b588be":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a2e54e29b0b045d68e4264d9d6be471b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"baef1b2b28ee460fbcdf5cdf389edd2f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bee2db720c6d48a2b2d4dd90681252e7","placeholder":"​","style":"IPY_MODEL_a2e54e29b0b045d68e4264d9d6be471b","value":" 100/100 [00:06&lt;00:00, 20.99it/s]"}},"bee2db720c6d48a2b2d4dd90681252e7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d631119f4021432d913a6a2559c1122e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}}}}},"nbformat":4,"nbformat_minor":0}
